{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_binary_vectors (generic function with 4 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"../src/HDC.jl\")\n",
    "include(\"../src/math.jl\")\n",
    "include(\"../src/experimental.jl\")\n",
    "using DataFrames\n",
    "using CSV\n",
    "using JLD\n",
    "using MultivariateStats\n",
    "using Evolutionary\n",
    "using Distances\n",
    "using Random\n",
    "using BioAlignments\n",
    "\n",
    "function fitness_func(individual, distance_matrix, dim)\n",
    "    num_vectors = size(distance_matrix, 1)\n",
    "    binary_vectors = transpose(reshape(individual, (dim, num_vectors)))\n",
    "    distances = zeros((num_vectors, num_vectors))\n",
    "    \n",
    "    Threads.@threads for i in 1:num_vectors\n",
    "        for j in 1:num_vectors\n",
    "            if i != j\n",
    "                distances[i, j] = Distances.hamming(Vector{Int}(binary_vectors[i, :]), Vector{Int}(binary_vectors[j, :]))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return sum((distances - distance_matrix).^2)\n",
    "end\n",
    "\n",
    "function generate_initial_population(population_size, dim, num_vectors)\n",
    "    return [bitrand(dim*num_vectors) for i in 1:population_size]\n",
    "end\n",
    "\n",
    "function generate_binary_vectors(dim, num_vectors, distance_matrix, max_generations=300, population_size=100, mutation_rate = 0.05)\n",
    "\n",
    "    opts = Evolutionary.Options(iterations=max_generations, parallelization=:thread)\n",
    "\n",
    "    ga = GA(\n",
    "        populationSize=population_size,\n",
    "        crossoverRate=0.99,\n",
    "        mutationRate=mutation_rate,\n",
    "        crossover=SPX,\n",
    "        mutation=flip\n",
    "    )\n",
    "    \n",
    "    objective = individual -> fitness_func(individual, distance_matrix, dim)\n",
    "\n",
    "    initial_population = generate_initial_population(population_size, dim, num_vectors)\n",
    "\n",
    "    result = Evolutionary.optimize(objective, initial_population, ga, opts)\n",
    "    best_individual = result.minimizer\n",
    "    best_solution = reshape(best_individual, (dim, num_vectors))\n",
    "\n",
    "    return transpose(best_solution)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_best_binary_vectors (generic function with 4 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Printf\n",
    "\n",
    "function similarity_error(desired_distance_matrix, calculated_distance_matrix)\n",
    "    return sum((calculated_distance_matrix .- desired_distance_matrix).^2)\n",
    "end\n",
    "\n",
    "function find_best_binary_vectors(dim, num_vectors, distance_matrix, num_trials, max_generations=300, population_size=100, mutation_rate = 0.05)\n",
    "    best_error = Inf\n",
    "    best_vectors = nothing\n",
    "    best_calculated_distance_matrix = nothing\n",
    "\n",
    "    for trial in 1:num_trials\n",
    "        binary_vectors = generate_binary_vectors(dim, num_vectors, distance_matrix, max_generations, population_size, mutation_rate)\n",
    "        calculated_distance_matrix = zeros((num_vectors, num_vectors))\n",
    "\n",
    "        for i in 1:num_vectors\n",
    "            for j in 1:num_vectors\n",
    "                if i != j\n",
    "                    hamming_distance = hamming(Vector{Int}(binary_vectors[i, :]), Vector{Int}(binary_vectors[j, :]))\n",
    "                    calculated_distance_matrix[i, j] = hamming_distance / dim\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "        error = similarity_error(distance_matrix, calculated_distance_matrix)\n",
    "\n",
    "        if error < best_error\n",
    "            best_error = error\n",
    "            best_vectors = binary_vectors\n",
    "            best_calculated_distance_matrix = calculated_distance_matrix\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return best_vectors, best_calculated_distance_matrix, best_error\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired pairwise similarities between the 20 vectors\n",
    "distance_matrix = [\n",
    "    0.0 0.2 0.4 0.6 0.8;\n",
    "    0.2 0.0 0.3 0.5 0.7;\n",
    "    0.4 0.3 0.0 0.2 0.4;\n",
    "    0.6 0.5 0.2 0.0 0.2;\n",
    "    0.8 0.7 0.4 0.2 0.0]\n",
    "\n",
    "# Generate binary vectors using the desired pairwise similarities\n",
    "dim = 10000\n",
    "num_vectors = size(distance_matrix, 1)\n",
    "num_trials = 30\n",
    "\n",
    "best_vectors, best_calculated_distance_matrix, best_error = find_best_binary_vectors(dim, num_vectors, distance_matrix, num_trials)\n",
    "\n",
    "println(\"Desired pairwise similarities:\")\n",
    "println(distance_matrix)\n",
    "\n",
    "println(\"\\nBest generated binary vectors:\")\n",
    "println(best_vectors)\n",
    "\n",
    "println(\"\\nBest calculated pairwise similarities:\")\n",
    "println(best_calculated_distance_matrix)\n",
    "\n",
    "@printf(\"\\nBest error: %f\", best_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Char}:\n",
       " 'A': ASCII/Unicode U+0041 (category Lu: Letter, uppercase)\n",
       " 'C': ASCII/Unicode U+0043 (category Lu: Letter, uppercase)\n",
       " 'D': ASCII/Unicode U+0044 (category Lu: Letter, uppercase)\n",
       " 'E': ASCII/Unicode U+0045 (category Lu: Letter, uppercase)\n",
       " 'F': ASCII/Unicode U+0046 (category Lu: Letter, uppercase)\n",
       " 'G': ASCII/Unicode U+0047 (category Lu: Letter, uppercase)\n",
       " 'H': ASCII/Unicode U+0048 (category Lu: Letter, uppercase)\n",
       " 'I': ASCII/Unicode U+0049 (category Lu: Letter, uppercase)\n",
       " 'K': ASCII/Unicode U+004B (category Lu: Letter, uppercase)\n",
       " 'L': ASCII/Unicode U+004C (category Lu: Letter, uppercase)\n",
       " 'M': ASCII/Unicode U+004D (category Lu: Letter, uppercase)\n",
       " 'N': ASCII/Unicode U+004E (category Lu: Letter, uppercase)\n",
       " 'P': ASCII/Unicode U+0050 (category Lu: Letter, uppercase)\n",
       " 'Q': ASCII/Unicode U+0051 (category Lu: Letter, uppercase)\n",
       " 'R': ASCII/Unicode U+0052 (category Lu: Letter, uppercase)\n",
       " 'S': ASCII/Unicode U+0053 (category Lu: Letter, uppercase)\n",
       " 'T': ASCII/Unicode U+0054 (category Lu: Letter, uppercase)\n",
       " 'V': ASCII/Unicode U+0056 (category Lu: Letter, uppercase)\n",
       " 'W': ASCII/Unicode U+0057 (category Lu: Letter, uppercase)\n",
       " 'Y': ASCII/Unicode U+0059 (category Lu: Letter, uppercase)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AA_list = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubstitutionMatrix{BioSymbols.AminoAcid, Int64}:\n",
       "     A  R  N  D  C  Q  E  G  H  I  L  K  M  F  P  S  T  W  Y  V  O  U  B  J  Z  X  *\n",
       "  A  4 -1 -2 -2  0 -1 -1  0 -2 -1 -1 -1 -1 -2 -1  1  0 -3 -2  0  0̲  0̲ -2  0̲ -1  0 -4\n",
       "  R -1  5  0 -2 -3  1  0 -2  0 -3 -2  2 -1 -3 -2 -1 -1 -3 -2 -3  0̲  0̲ -1  0̲  0 -1 -4\n",
       "  N -2  0  6  1 -3  0  0  0  1 -3 -3  0 -2 -3 -2  1  0 -4 -2 -3  0̲  0̲  3  0̲  0 -1 -4\n",
       "  D -2 -2  1  6 -3  0  2 -1 -1 -3 -4 -1 -3 -3 -1  0 -1 -4 -3 -3  0̲  0̲  4  0̲  1 -1 -4\n",
       "  C  0 -3 -3 -3  9 -3 -4 -3 -3 -1 -1 -3 -1 -2 -3 -1 -1 -2 -2 -1  0̲  0̲ -3  0̲ -3 -2 -4\n",
       "  Q -1  1  0  0 -3  5  2 -2  0 -3 -2  1  0 -3 -1  0 -1 -2 -1 -2  0̲  0̲  0  0̲  3 -1 -4\n",
       "  E -1  0  0  2 -4  2  5 -2  0 -3 -3  1 -2 -3 -1  0 -1 -3 -2 -2  0̲  0̲  1  0̲  4 -1 -4\n",
       "  G  0 -2  0 -1 -3 -2 -2  6 -2 -4 -4 -2 -3 -3 -2  0 -2 -2 -3 -3  0̲  0̲ -1  0̲ -2 -1 -4\n",
       "  H -2  0  1 -1 -3  0  0 -2  8 -3 -3 -1 -2 -1 -2 -1 -2 -2  2 -3  0̲  0̲  0  0̲  0 -1 -4\n",
       "  I -1 -3 -3 -3 -1 -3 -3 -4 -3  4  2 -3  1  0 -3 -2 -1 -3 -1  3  0̲  0̲ -3  0̲ -3 -1 -4\n",
       "  L -1 -2 -3 -4 -1 -2 -3 -4 -3  2  4 -2  2  0 -3 -2 -1 -2 -1  1  0̲  0̲ -4  0̲ -3 -1 -4\n",
       "  K -1  2  0 -1 -3  1  1 -2 -1 -3 -2  5 -1 -3 -1  0 -1 -3 -2 -2  0̲  0̲  0  0̲  1 -1 -4\n",
       "  M -1 -1 -2 -3 -1  0 -2 -3 -2  1  2 -1  5  0 -2 -1 -1 -1 -1  1  0̲  0̲ -3  0̲ -1 -1 -4\n",
       "  F -2 -3 -3 -3 -2 -3 -3 -3 -1  0  0 -3  0  6 -4 -2 -2  1  3 -1  0̲  0̲ -3  0̲ -3 -1 -4\n",
       "  P -1 -2 -2 -1 -3 -1 -1 -2 -2 -3 -3 -1 -2 -4  7 -1 -1 -4 -3 -2  0̲  0̲ -2  0̲ -1 -2 -4\n",
       "  S  1 -1  1  0 -1  0  0  0 -1 -2 -2  0 -1 -2 -1  4  1 -3 -2 -2  0̲  0̲  0  0̲  0  0 -4\n",
       "  T  0 -1  0 -1 -1 -1 -1 -2 -2 -1 -1 -1 -1 -2 -1  1  5 -2 -2  0  0̲  0̲ -1  0̲ -1  0 -4\n",
       "  W -3 -3 -4 -4 -2 -2 -3 -2 -2 -3 -2 -3 -1  1 -4 -3 -2 11  2 -3  0̲  0̲ -4  0̲ -3 -2 -4\n",
       "  Y -2 -2 -2 -3 -2 -1 -2 -3  2 -1 -1 -2 -1  3 -3 -2 -2  2  7 -1  0̲  0̲ -3  0̲ -2 -1 -4\n",
       "  V  0 -3 -3 -3 -1 -2 -2 -3 -3  3  1 -2  1 -1 -2 -2  0 -3 -1  4  0̲  0̲ -3  0̲ -2 -1 -4\n",
       "  O  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲\n",
       "  U  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲\n",
       "  B -2 -1  3  4 -3  0  1 -1  0 -3 -4  0 -3 -3 -2  0 -1 -4 -3 -3  0̲  0̲  4  0̲  1 -1 -4\n",
       "  J  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲  0̲\n",
       "  Z -1  0  0  1 -3  3  4 -2  0 -3 -3  1 -1 -3 -1  0 -1 -3 -2 -2  0̲  0̲  1  0̲  4 -1 -4\n",
       "  X  0 -1 -1 -1 -2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -2  0  0 -2 -1 -1  0̲  0̲ -1  0̲ -1 -1 -4\n",
       "  * -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4  0̲  0̲ -4  0̲ -4 -4  1\n",
       "(underlined values are default ones)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simmat = copy(GRANTHAM1974)\n",
    "simmatblo = copy(BLOSUM62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20×20 Matrix{Int64}:\n",
       "  4   0  -2  -1  -2   0  -2  -1  -1  …  -2  -1  -1  -1   1   0   0  -3  -2\n",
       "  0   9  -3  -4  -2  -3  -3  -1  -3     -3  -3  -3  -3  -1  -1  -1  -2  -2\n",
       " -2  -3   6   2  -3  -1  -1  -3  -1      1  -1   0  -2   0  -1  -3  -4  -3\n",
       " -1  -4   2   5  -3  -2   0  -3   1      0  -1   2   0   0  -1  -2  -3  -2\n",
       " -2  -2  -3  -3   6  -3  -1   0  -3     -3  -4  -3  -3  -2  -2  -1   1   3\n",
       "  0  -3  -1  -2  -3   6  -2  -4  -2  …   0  -2  -2  -2   0  -2  -3  -2  -3\n",
       " -2  -3  -1   0  -1  -2   8  -3  -1      1  -2   0   0  -1  -2  -3  -2   2\n",
       " -1  -1  -3  -3   0  -4  -3   4  -3     -3  -3  -3  -3  -2  -1   3  -3  -1\n",
       " -1  -3  -1   1  -3  -2  -1  -3   5      0  -1   1   2   0  -1  -2  -3  -2\n",
       " -1  -1  -4  -3   0  -4  -3   2  -2     -3  -3  -2  -2  -2  -1   1  -2  -1\n",
       " -1  -1  -3  -2   0  -3  -2   1  -1  …  -2  -2   0  -1  -1  -1   1  -1  -1\n",
       " -2  -3   1   0  -3   0   1  -3   0      6  -2   0   0   1   0  -3  -4  -2\n",
       " -1  -3  -1  -1  -4  -2  -2  -3  -1     -2   7  -1  -2  -1  -1  -2  -4  -3\n",
       " -1  -3   0   2  -3  -2   0  -3   1      0  -1   5   1   0  -1  -2  -2  -1\n",
       " -1  -3  -2   0  -3  -2   0  -3   2      0  -2   1   5  -1  -1  -3  -3  -2\n",
       "  1  -1   0   0  -2   0  -1  -2   0  …   1  -1   0  -1   4   1  -2  -3  -2\n",
       "  0  -1  -1  -1  -2  -2  -2  -1  -1      0  -1  -1  -1   1   5   0  -2  -2\n",
       "  0  -1  -3  -2  -1  -3  -3   3  -2     -3  -2  -2  -3  -2   0   4  -3  -1\n",
       " -3  -2  -4  -3   1  -2  -2  -3  -3     -4  -4  -2  -3  -3  -2  -3  11   2\n",
       " -2  -2  -3  -2   3  -3   2  -1  -2     -2  -3  -1  -2  -2  -2  -1   2   7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grantham = [[simmat[i, j] for i in AA_list] for j in AA_list]\n",
    "grantham = hcat(grantham...)\n",
    "\n",
    "blosum = [[simmatblo[i, j] for i in AA_list] for j in AA_list]\n",
    "blosum = hcat(blosum...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "norm_mat (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function norm_mat(matrix, zero=false)\n",
    "    if zero == true\n",
    "        min_value = 0\n",
    "    else \n",
    "        min_value = minimum(matrix)\n",
    "    end\n",
    "    \n",
    "    max_value = maximum(matrix)\n",
    "\n",
    "    normalized_matrix = (matrix .- min_value) ./ (max_value - min_value)\n",
    "    return normalized_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20×20 Matrix{Int64}:\n",
       "   0  195  126  107  113   60   86   94  …   91  112   99   58   64  148  112\n",
       " 195    0  154  170  205  159  174  198     154  180  112  149  192  215  194\n",
       " 126  154    0   45  177   94   81  168      61   96   65   85  152  181  160\n",
       " 107  170   45    0  140   98   40  134      29   54   80   65  121  152  122\n",
       " 113  205  177  140    0  153  100   21     116   97  155  103   50   40   22\n",
       "  60  159   94   98  153    0   98  135  …   87  125   56   59  109  184  147\n",
       "  86  174   81   40  100   98    0   94      24   29   89   47   84  115   83\n",
       "  94  198  168  134   21  135   94    0     109   97  142   89   29   61   33\n",
       " 106  202  101   56  102  127   32  102      53   26  121   78   97  110   85\n",
       "  96  198  172  138   22  138   99    5     113  102  145   92   32   61   36\n",
       "  84  196  160  126   28  127   87   10  …  101   91  135   81   21   67   36\n",
       " 111  139   23   42  158   80   68  149      46   86   46   65  133  174  143\n",
       "  27  169  108   93  114   42   77   95      76  103   74   38   68  147  110\n",
       "  91  154   61   29  116   87   24  109       0   43   68   42   96  130   99\n",
       " 112  180   96   54   97  125   29   97      43    0  110   71   96  101   77\n",
       "  99  112   65   80  155   56   89  142  …   68  110    0   58  124  177  144\n",
       "  58  149   85   65  103   59   47   89      42   71   58    0   69  128   92\n",
       "  64  192  152  121   50  109   84   29      96   96  124   69    0   88   55\n",
       " 148  215  181  152   40  184  115   61     130  101  177  128   88    0   37\n",
       " 112  194  160  122   22  147   83   33      99   77  144   92   55   37    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grantham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20×20 Matrix{Float64}:\n",
       " 0.0       0.906977  0.586047  0.497674  …  0.297674   0.688372  0.52093\n",
       " 0.906977  0.0       0.716279  0.790698     0.893023   1.0       0.902326\n",
       " 0.586047  0.716279  0.0       0.209302     0.706977   0.84186   0.744186\n",
       " 0.497674  0.790698  0.209302  0.0          0.562791   0.706977  0.567442\n",
       " 0.525581  0.953488  0.823256  0.651163     0.232558   0.186047  0.102326\n",
       " 0.27907   0.739535  0.437209  0.455814  …  0.506977   0.855814  0.683721\n",
       " 0.4       0.809302  0.376744  0.186047     0.390698   0.534884  0.386047\n",
       " 0.437209  0.92093   0.781395  0.623256     0.134884   0.283721  0.153488\n",
       " 0.493023  0.939535  0.469767  0.260465     0.451163   0.511628  0.395349\n",
       " 0.446512  0.92093   0.8       0.64186      0.148837   0.283721  0.167442\n",
       " 0.390698  0.911628  0.744186  0.586047  …  0.0976744  0.311628  0.167442\n",
       " 0.516279  0.646512  0.106977  0.195349     0.618605   0.809302  0.665116\n",
       " 0.125581  0.786047  0.502326  0.432558     0.316279   0.683721  0.511628\n",
       " 0.423256  0.716279  0.283721  0.134884     0.446512   0.604651  0.460465\n",
       " 0.52093   0.837209  0.446512  0.251163     0.446512   0.469767  0.35814\n",
       " 0.460465  0.52093   0.302326  0.372093  …  0.576744   0.823256  0.669767\n",
       " 0.269767  0.693023  0.395349  0.302326     0.32093    0.595349  0.427907\n",
       " 0.297674  0.893023  0.706977  0.562791     0.0        0.409302  0.255814\n",
       " 0.688372  1.0       0.84186   0.706977     0.409302   0.0       0.172093\n",
       " 0.52093   0.902326  0.744186  0.567442     0.255814   0.172093  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_blosum = broadcast(abs, norm_mat(blosum) .-1)\n",
    "setindex!.(Ref(norm_blosum), 0.0, 1:20, 1:20)\n",
    "norm_grant = norm_mat(grantham, true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TaskFailedException",
     "evalue": "TaskFailedException\n\n    nested task error: TaskFailedException\n    Stacktrace:\n      [1] wait\n        @ ./task.jl:345 [inlined]\n      [2] threading_run(fun::var\"#146#threadsfor_fun#133\"{var\"#146#threadsfor_fun#132#134\"{Matrix{Float64}, Transpose{Bool, BitMatrix}, Int64, UnitRange{Int64}}}, static::Bool)\n        @ Base.Threads ./threadingconstructs.jl:38\n      [3] macro expansion\n        @ ./threadingconstructs.jl:89 [inlined]\n      [4] fitness_func(individual::BitVector, distance_matrix::Matrix{Float64}, dim::Int64)\n        @ Main ~/Master-Thesis/notebooks/AA_em2.ipynb:18\n      [5] #137\n        @ ~/Master-Thesis/notebooks/AA_em2.ipynb:45 [inlined]\n      [6] value\n        @ ~/.julia/packages/Evolutionary/65hL6/src/api/objective.jl:52 [inlined]\n      [7] macro expansion\n        @ ~/.julia/packages/Evolutionary/65hL6/src/api/objective.jl:90 [inlined]\n      [8] (::Evolutionary.var\"#37#threadsfor_fun#10\"{Evolutionary.var\"#37#threadsfor_fun#9#11\"{EvolutionaryObjective{var\"#137#138\"{Int64, Matrix{Float64}}, Float64, BitVector, Val{:thread}}, Vector{Float64}, Vector{BitVector}, UnitRange{Int64}}})(tid::Int64; onethread::Bool)\n        @ Evolutionary ./threadingconstructs.jl:84\n      [9] #37#threadsfor_fun\n        @ ./threadingconstructs.jl:51 [inlined]\n     [10] (::Base.Threads.var\"#1#2\"{Evolutionary.var\"#37#threadsfor_fun#10\"{Evolutionary.var\"#37#threadsfor_fun#9#11\"{EvolutionaryObjective{var\"#137#138\"{Int64, Matrix{Float64}}, Float64, BitVector, Val{:thread}}, Vector{Float64}, Vector{BitVector}, UnitRange{Int64}}}, Int64})()\n        @ Base.Threads ./threadingconstructs.jl:30\n    \n        nested task error: InterruptException:\n        Stacktrace:\n          [1] Array\n            @ ./boot.jl:459 [inlined]\n          [2] BitArray\n            @ ./bitarray.jl:37 [inlined]\n          [3] BitArray\n            @ ./bitarray.jl:71 [inlined]\n          [4] similar\n            @ ./bitarray.jl:372 [inlined]\n          [5] similar\n            @ ~/.julia/juliaup/julia-1.8.5+0.x64.linux.gnu/share/julia/stdlib/v1.8/LinearAlgebra/src/adjtrans.jl:212 [inlined]\n          [6] similar\n            @ ./abstractarray.jl:795 [inlined]\n          [7] _unsafe_getindex(::IndexCartesian, ::Transpose{Bool, BitMatrix}, ::Int64, ::Base.Slice{Base.OneTo{Int64}})\n            @ Base ./multidimensional.jl:887\n          [8] _getindex\n            @ ./multidimensional.jl:875 [inlined]\n          [9] getindex\n            @ ./abstractarray.jl:1241 [inlined]\n         [10] macro expansion\n            @ ~/Master-Thesis/notebooks/AA_em2.ipynb:21 [inlined]\n         [11] (::var\"#146#threadsfor_fun#133\"{var\"#146#threadsfor_fun#132#134\"{Matrix{Float64}, Transpose{Bool, BitMatrix}, Int64, UnitRange{Int64}}})(tid::Int64; onethread::Bool)\n            @ Main ./threadingconstructs.jl:84\n         [12] #146#threadsfor_fun\n            @ ./threadingconstructs.jl:51 [inlined]\n         [13] (::Base.Threads.var\"#1#2\"{var\"#146#threadsfor_fun#133\"{var\"#146#threadsfor_fun#132#134\"{Matrix{Float64}, Transpose{Bool, BitMatrix}, Int64, UnitRange{Int64}}}, Int64})()\n            @ Base.Threads ./threadingconstructs.jl:30",
     "output_type": "error",
     "traceback": [
      "TaskFailedException\n",
      "\n",
      "    nested task error: TaskFailedException\n",
      "    Stacktrace:\n",
      "      [1] wait\n",
      "        @ ./task.jl:345 [inlined]\n",
      "      [2] threading_run(fun::var\"#146#threadsfor_fun#133\"{var\"#146#threadsfor_fun#132#134\"{Matrix{Float64}, Transpose{Bool, BitMatrix}, Int64, UnitRange{Int64}}}, static::Bool)\n",
      "        @ Base.Threads ./threadingconstructs.jl:38\n",
      "      [3] macro expansion\n",
      "        @ ./threadingconstructs.jl:89 [inlined]\n",
      "      [4] fitness_func(individual::BitVector, distance_matrix::Matrix{Float64}, dim::Int64)\n",
      "        @ Main ~/Master-Thesis/notebooks/AA_em2.ipynb:18\n",
      "      [5] #137\n",
      "        @ ~/Master-Thesis/notebooks/AA_em2.ipynb:45 [inlined]\n",
      "      [6] value\n",
      "        @ ~/.julia/packages/Evolutionary/65hL6/src/api/objective.jl:52 [inlined]\n",
      "      [7] macro expansion\n",
      "        @ ~/.julia/packages/Evolutionary/65hL6/src/api/objective.jl:90 [inlined]\n",
      "      [8] (::Evolutionary.var\"#37#threadsfor_fun#10\"{Evolutionary.var\"#37#threadsfor_fun#9#11\"{EvolutionaryObjective{var\"#137#138\"{Int64, Matrix{Float64}}, Float64, BitVector, Val{:thread}}, Vector{Float64}, Vector{BitVector}, UnitRange{Int64}}})(tid::Int64; onethread::Bool)\n",
      "        @ Evolutionary ./threadingconstructs.jl:84\n",
      "      [9] #37#threadsfor_fun\n",
      "        @ ./threadingconstructs.jl:51 [inlined]\n",
      "     [10] (::Base.Threads.var\"#1#2\"{Evolutionary.var\"#37#threadsfor_fun#10\"{Evolutionary.var\"#37#threadsfor_fun#9#11\"{EvolutionaryObjective{var\"#137#138\"{Int64, Matrix{Float64}}, Float64, BitVector, Val{:thread}}, Vector{Float64}, Vector{BitVector}, UnitRange{Int64}}}, Int64})()\n",
      "        @ Base.Threads ./threadingconstructs.jl:30\n",
      "    \n",
      "        nested task error: InterruptException:\n",
      "        Stacktrace:\n",
      "          [1] Array\n",
      "            @ ./boot.jl:459 [inlined]\n",
      "          [2] BitArray\n",
      "            @ ./bitarray.jl:37 [inlined]\n",
      "          [3] BitArray\n",
      "            @ ./bitarray.jl:71 [inlined]\n",
      "          [4] similar\n",
      "            @ ./bitarray.jl:372 [inlined]\n",
      "          [5] similar\n",
      "            @ ~/.julia/juliaup/julia-1.8.5+0.x64.linux.gnu/share/julia/stdlib/v1.8/LinearAlgebra/src/adjtrans.jl:212 [inlined]\n",
      "          [6] similar\n",
      "            @ ./abstractarray.jl:795 [inlined]\n",
      "          [7] _unsafe_getindex(::IndexCartesian, ::Transpose{Bool, BitMatrix}, ::Int64, ::Base.Slice{Base.OneTo{Int64}})\n",
      "            @ Base ./multidimensional.jl:887\n",
      "          [8] _getindex\n",
      "            @ ./multidimensional.jl:875 [inlined]\n",
      "          [9] getindex\n",
      "            @ ./abstractarray.jl:1241 [inlined]\n",
      "         [10] macro expansion\n",
      "            @ ~/Master-Thesis/notebooks/AA_em2.ipynb:21 [inlined]\n",
      "         [11] (::var\"#146#threadsfor_fun#133\"{var\"#146#threadsfor_fun#132#134\"{Matrix{Float64}, Transpose{Bool, BitMatrix}, Int64, UnitRange{Int64}}})(tid::Int64; onethread::Bool)\n",
      "            @ Main ./threadingconstructs.jl:84\n",
      "         [12] #146#threadsfor_fun\n",
      "            @ ./threadingconstructs.jl:51 [inlined]\n",
      "         [13] (::Base.Threads.var\"#1#2\"{var\"#146#threadsfor_fun#133\"{var\"#146#threadsfor_fun#132#134\"{Matrix{Float64}, Transpose{Bool, BitMatrix}, Int64, UnitRange{Int64}}}, Int64})()\n",
      "            @ Base.Threads ./threadingconstructs.jl:30\n",
      "\n",
      "Stacktrace:\n",
      "  [1] wait\n",
      "    @ ./task.jl:345 [inlined]\n",
      "  [2] threading_run(fun::Evolutionary.var\"#37#threadsfor_fun#10\"{Evolutionary.var\"#37#threadsfor_fun#9#11\"{EvolutionaryObjective{var\"#137#138\"{Int64, Matrix{Float64}}, Float64, BitVector, Val{:thread}}, Vector{Float64}, Vector{BitVector}, UnitRange{Int64}}}, static::Bool)\n",
      "    @ Base.Threads ./threadingconstructs.jl:38\n",
      "  [3] macro expansion\n",
      "    @ ./threadingconstructs.jl:89 [inlined]\n",
      "  [4] value!\n",
      "    @ ~/.julia/packages/Evolutionary/65hL6/src/api/objective.jl:89 [inlined]\n",
      "  [5] evaluate!\n",
      "    @ ~/.julia/packages/Evolutionary/65hL6/src/ga.jl:129 [inlined]\n",
      "  [6] update_state!(objfun::EvolutionaryObjective{var\"#137#138\"{Int64, Matrix{Float64}}, Float64, BitVector, Val{:thread}}, constraints::Evolutionary.NoConstraints, state::Evolutionary.GAState{Float64, BitVector}, parents::Vector{BitVector}, method::GA{Evolutionary.var\"#tournamentN#267\"{Evolutionary.var\"#tournamentN#266#268\"{typeof(argmin), Int64}}, typeof(SPX), typeof(flip)}, options::Evolutionary.Options{Nothing, TaskLocalRNG}, itr::Int64)\n",
      "    @ Evolutionary ~/.julia/packages/Evolutionary/65hL6/src/ga.jl:89\n",
      "  [7] optimize(objfun::EvolutionaryObjective{var\"#137#138\"{Int64, Matrix{Float64}}, Float64, BitVector, Val{:thread}}, constraints::Evolutionary.NoConstraints, method::GA{Evolutionary.var\"#tournamentN#267\"{Evolutionary.var\"#tournamentN#266#268\"{typeof(argmin), Int64}}, typeof(SPX), typeof(flip)}, population::Vector{BitVector}, options::Evolutionary.Options{Nothing, TaskLocalRNG}, state::Evolutionary.GAState{Float64, BitVector})\n",
      "    @ Evolutionary ~/.julia/packages/Evolutionary/65hL6/src/api/optimize.jl:105\n",
      "  [8] optimize(objfun::EvolutionaryObjective{var\"#137#138\"{Int64, Matrix{Float64}}, Float64, BitVector, Val{:thread}}, constraints::Evolutionary.NoConstraints, method::GA{Evolutionary.var\"#tournamentN#267\"{Evolutionary.var\"#tournamentN#266#268\"{typeof(argmin), Int64}}, typeof(SPX), typeof(flip)}, population::Vector{BitVector}, options::Evolutionary.Options{Nothing, TaskLocalRNG})\n",
      "    @ Evolutionary ~/.julia/packages/Evolutionary/65hL6/src/api/optimize.jl:70\n",
      "  [9] optimize(f::var\"#137#138\"{Int64, Matrix{Float64}}, constraints::Evolutionary.NoConstraints, method::GA{Evolutionary.var\"#tournamentN#267\"{Evolutionary.var\"#tournamentN#266#268\"{typeof(argmin), Int64}}, typeof(SPX), typeof(flip)}, population::Vector{BitVector}, opts::Evolutionary.Options{Nothing, TaskLocalRNG})\n",
      "    @ Evolutionary ~/.julia/packages/Evolutionary/65hL6/src/api/optimize.jl:55\n",
      " [10] optimize\n",
      "    @ ~/.julia/packages/Evolutionary/65hL6/src/api/optimize.jl:42 [inlined]\n",
      " [11] optimize\n",
      "    @ ~/.julia/packages/Evolutionary/65hL6/src/api/optimize.jl:15 [inlined]\n",
      " [12] generate_binary_vectors(dim::Int64, num_vectors::Int64, distance_matrix::Matrix{Float64}, max_generations::Int64, population_size::Int64, mutation_rate::Float64)\n",
      "    @ Main ~/Master-Thesis/notebooks/AA_em2.ipynb:49\n",
      " [13] find_best_binary_vectors(dim::Int64, num_vectors::Int64, distance_matrix::Matrix{Float64}, num_trials::Int64, max_generations::Int64, population_size::Int64, mutation_rate::Float64)\n",
      "    @ Main ~/Master-Thesis/notebooks/AA_em2.ipynb:13\n",
      " [14] find_best_binary_vectors(dim::Int64, num_vectors::Int64, distance_matrix::Matrix{Float64}, num_trials::Int64, max_generations::Int64, population_size::Int64)\n",
      "    @ Main ~/Master-Thesis/notebooks/AA_em2.ipynb:8\n",
      " [15] top-level scope\n",
      "    @ ~/Master-Thesis/notebooks/AA_em2.ipynb:7"
     ]
    }
   ],
   "source": [
    "distance_matrix = norm_blosum\n",
    "# Generate binary vectors using the desired pairwise similarities\n",
    "dim = 10000\n",
    "num_vectors = size(distance_matrix, 1)\n",
    "num_trials = 100\n",
    "\n",
    "best_vectors, best_calculated_distance_matrix, best_error = find_best_binary_vectors(dim, num_vectors, distance_matrix, num_trials, 500, 500)\n",
    "\n",
    "println(\"Desired pairwise similarities:\")\n",
    "println(distance_matrix)\n",
    "\n",
    "println(\"\\nBest generated binary vectors:\")\n",
    "println(best_vectors)\n",
    "\n",
    "println(\"\\nBest calculated pairwise similarities:\")\n",
    "println(best_calculated_distance_matrix)\n",
    "\n",
    "@printf(\"\\nBest error: %f\", best_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = norm_grantham\n",
    "# Generate binary vectors using the desired pairwise similarities\n",
    "dim = 10000\n",
    "num_vectors = size(distance_matrix, 1)\n",
    "num_trials = 100\n",
    "\n",
    "gr_best_vectors, gr_best_calculated_distance_matrix, gr_best_error = find_best_binary_vectors(dim, num_vectors, distance_matrix, num_trials, 500, 500)\n",
    "\n",
    "println(\"Desired pairwise similarities:\")\n",
    "println(distance_matrix)\n",
    "\n",
    "println(\"\\nBest generated binary vectors:\")\n",
    "println(gr_best_vectors)\n",
    "\n",
    "println(\"\\nBest calculated pairwise similarities:\")\n",
    "println(gr_best_calculated_distance_matrix)\n",
    "\n",
    "@printf(\"\\nBest error: %f\", gr_best_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
