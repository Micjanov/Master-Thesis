{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: type InlineStrings.String15 not present in workspace; reconstructing\n",
      "└ @ JLD /home/mfat/.julia/packages/JLD/S6t6A/src/jld_types.jl:697\n",
      "┌ Warning: type InlineStrings.String31 not present in workspace; reconstructing\n",
      "└ @ JLD /home/mfat/.julia/packages/JLD/S6t6A/src/jld_types.jl:697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: type InlineStrings.String31 not present in workspace; reconstructing\n",
      "└ @ JLD /home/mfat/.julia/packages/JLD/S6t6A/src/jld_types.jl:697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{String, Union{Missing, String}} with 11549 entries:\n",
       "  \"UPI000178DD30\" => \"endolysin\"\n",
       "  \"UPI0013EFDC93\" => \"endolysin\"\n",
       "  \"UPI000172D062\" => \"VAL\"\n",
       "  \"UPI001463ABBB\" => \"endolysin\"\n",
       "  \"UPI000232F56D\" => \"endolysin\"\n",
       "  \"UPI0011625D30\" => \"VAL\"\n",
       "  \"UPI0009882324\" => \"endolysin\"\n",
       "  \"UPI000CA1D611\" => \"VAL\"\n",
       "  \"UPI0006BC2F8A\" => \"endolysin\"\n",
       "  \"UPI000BBF7878\" => \"endolysin\"\n",
       "  \"UPI00138B2696\" => \"endolysin\"\n",
       "  \"UPI00025D6AED\" => \"endolysin\"\n",
       "  \"UPI0010C2D3EE\" => \"endolysin\"\n",
       "  \"UPI000D22144F\" => \"VAL\"\n",
       "  \"UPI0018623B24\" => \"endolysin\"\n",
       "  \"UPI00080F0655\" => \"endolysin\"\n",
       "  \"UPI00022BD3A3\" => \"endolysin\"\n",
       "  \"UPI0008093543\" => \"endolysin\"\n",
       "  \"UPI001463E938\" => \"VAL\"\n",
       "  ⋮               => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"../src/HDC.jl\")\n",
    "include(\"../src/math.jl\")\n",
    "include(\"../src/experimental.jl\")\n",
    "using JLD\n",
    "\n",
    "phalp_bow_esm = load(\"../data/phalp_bow_esm.jld\")[\"embedded_bow_esm\"]\n",
    "phalp_bow_rand = load(\"../data/phalp_bow_rand.jld\")[\"embedded_rand_bow\"]\n",
    "phalp_cnn_esm = load(\"../data/phalp_CNN_esm.jld\")[\"embedded_CNN_esm\"]\n",
    "upi2doms = load(\"../data/phalp_upi2doms.jld\")[\"upi2doms\"]\n",
    "domacc2domname = load(\"../data/phalp_domacc2domname.jld\")[\"domacc2domname\"]\n",
    "phalp_cnn_rand = load(\"../data/phalp_cnn_rand.jld\")[\"embedded_rand_CNN\"]\n",
    "non_ml = load(\"../data/phalp_non_ml.jld\")[\"up_evd_type\"]\n",
    "ml_pred = load(\"../data/phalp_ml.jld\")[\"up_evd_type_ML\"]\n",
    "up2type = load(\"../data/phalp_type.jld\")[\"up2type\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Union{Missing, String}} with 4829 entries:\n",
       "  \"UPI000178DD30\" => \"endolysin\"\n",
       "  \"UPI0012B4B15F\" => \"endolysin\"\n",
       "  \"UPI0013EFDC93\" => \"endolysin\"\n",
       "  \"UPI000201BE9F\" => \"endolysin\"\n",
       "  \"UPI000172D062\" => \"VAL\"\n",
       "  \"UPI000232F56D\" => \"endolysin\"\n",
       "  \"UPI0011625D30\" => \"VAL\"\n",
       "  \"UPI000CA1D611\" => \"VAL\"\n",
       "  \"UPI000DF0A1E1\" => \"endolysin\"\n",
       "  \"UPI00138B2696\" => \"endolysin\"\n",
       "  \"UPI000012EA4B\" => \"endolysin\"\n",
       "  \"UPI000D22144F\" => \"VAL\"\n",
       "  \"UPI001860540C\" => \"VAL\"\n",
       "  \"UPI001AF87A26\" => \"VAL\"\n",
       "  \"UPI000F4325E4\" => \"VAL\"\n",
       "  \"UPI0012AA2260\" => \"VAL\"\n",
       "  \"UPI000172D02D\" => \"VAL\"\n",
       "  \"UPI0005362DA9\" => \"VAL\"\n",
       "  \"UPI0004593892\" => \"VAL\"\n",
       "  ⋮               => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new = filter(x -> (first(x) in collect(keys(non_ml))), up2type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Union{Missing, String}} with 2803 entries:\n",
       "  \"UPI000178DD30\" => \"endolysin\"\n",
       "  \"UPI0012B4B15F\" => \"endolysin\"\n",
       "  \"UPI0013EFDC93\" => \"endolysin\"\n",
       "  \"UPI000201BE9F\" => \"endolysin\"\n",
       "  \"UPI000232F56D\" => \"endolysin\"\n",
       "  \"UPI000DF0A1E1\" => \"endolysin\"\n",
       "  \"UPI00138B2696\" => \"endolysin\"\n",
       "  \"UPI000012EA4B\" => \"endolysin\"\n",
       "  \"UPI000178C353\" => \"endolysin\"\n",
       "  \"UPI001436E76F\" => \"endolysin\"\n",
       "  \"UPI000F6BA7D8\" => \"endolysin\"\n",
       "  \"UPI00001A38F6\" => \"endolysin\"\n",
       "  \"UPI00001A9BAB\" => \"endolysin\"\n",
       "  \"UPI001435C02C\" => \"endolysin\"\n",
       "  \"UPI0010B96635\" => \"endolysin\"\n",
       "  \"UPI0015F22725\" => \"endolysin\"\n",
       "  \"UPI000D7DCFA8\" => \"endolysin\"\n",
       "  \"UPI0010B8D78B\" => \"endolysin\"\n",
       "  \"UPI000EB70E47\" => \"endolysin\"\n",
       "  ⋮               => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val = filter(x -> (last(x) == \"VAL\"), new)\n",
    "endo = filter(x -> (last(x) == \"endolysin\"), new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simp_trainer (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function simp_trainer(seq_dict, feature_dict)\n",
    "\"\"\"\n",
    "input: dict(names, sequences) and dict(names, class)\n",
    "\"\"\"\n",
    "\n",
    "    inv_fd = Dict()\n",
    "    for k in keys(feature_dict)\n",
    "        if feature_dict[k] in keys(inv_fd)\n",
    "            push!(inv_fd[feature_dict[k]],k)\n",
    "        else\n",
    "            inv_fd[feature_dict[k]] = [k]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    types = collect(keys(inv_fd))\n",
    "\n",
    "    class_hdvs = Dict()\n",
    "    for i in types\n",
    "        names_intr = inv_fd[i]\n",
    "        seq = [seq_dict[n] for n in names_intr]\n",
    "        class_hdvs[i] = bitadd(hcat(seq)...)\n",
    "    end\n",
    "\n",
    "    return class_hdvs\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simp_train2test (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function simp_train2test(seq, feature)\n",
    "    \"\"\"\n",
    "    input: dict(names, sequences) and dict(names, class)\n",
    "    \"\"\"\n",
    "        class_hdvs = Dict()\n",
    "        Threads.@threads for i in 1:length(feature)\n",
    "            if feature[i] in collect(keys(class_hdvs))\n",
    "                class_hdvs[feature[i]] = bitadd(class_hdvs[feature[i]], seq[i])\n",
    "            else\n",
    "                class_hdvs[feature[i]] = seq[i]\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        return class_hdvs\n",
    "    end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simp_test (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using MLDataPattern\n",
    "function simp_test(seq_dict, feature_dict)\n",
    "\"\"\"\n",
    "input: dict(names, sequences) and dict(names, class), output simp_trainer\n",
    "\"\"\"\n",
    "    Keys = [key for (key, val) in feature_dict]\n",
    "    key_seq = [seq_dict[i] for i in Keys]\n",
    "    Values = [val for (key, val) in feature_dict]\n",
    "\n",
    "    (X_train,y_train), (X_test,y_test) = stratifiedobs((key_seq, Values), p = 0.8)\n",
    "    classes = collect(Set(y_test))\n",
    "    println(classes)\n",
    "    n = length(classes)\n",
    "\n",
    "    class_ind = Dict()\n",
    "    Threads.@threads for i in 1:n\n",
    "        class_ind[classes[i]] = i\n",
    "    end\n",
    "\n",
    "    confusion_matrix = zeros(n,n)\n",
    "\n",
    "    class_hdv = simp_train2test(X_train, y_train)\n",
    "\n",
    "    Threads.@threads for i in 1:length(X_test)\n",
    "        for j in classes\n",
    "            simil = 0\n",
    "            pred = \"\"\n",
    "            new_simil = hamming(X_test[i], class_hdv[j])\n",
    "            if new_simil > simil\n",
    "                simil = new_simil\n",
    "                pred = j\n",
    "            end\n",
    "        end\n",
    "        confusion_matrix[class_ind[y_test[i]], class_ind[]] += 1\n",
    "    end\n",
    "    return confusion_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"VAL\", \"endolysin\"]\n"
     ]
    },
    {
     "ename": "TaskFailedException",
     "evalue": "TaskFailedException\n\n    nested task error: MethodError: no method matching getindex(::Dict{Any, Any})\n    Closest candidates are:\n      getindex(::Dict{K, V}, !Matched::Any) where {K, V} at dict.jl:496\n      getindex(::AbstractDict, !Matched::Any) at abstractdict.jl:533\n      getindex(::AbstractDict, !Matched::Any, !Matched::Any, !Matched::Any...) at abstractdict.jl:543\n    Stacktrace:\n     [1] macro expansion\n       @ ~/Master-Thesis/notebooks/PhaLP_traintest.ipynb:34 [inlined]\n     [2] (::var\"#278#threadsfor_fun#109\"{var\"#278#threadsfor_fun#103#110\"{Dict{Any, Any}, Matrix{Float64}, Dict{Any, Any}, Vector{String}, SubArray{String, 1, Vector{String}, Tuple{Vector{Int64}}, false}, SubArray{BitVector, 1, Vector{BitVector}, Tuple{Vector{Int64}}, false}, UnitRange{Int64}}})(tid::Int64; onethread::Bool)\n       @ Main ./threadingconstructs.jl:84\n     [3] #278#threadsfor_fun\n       @ ./threadingconstructs.jl:51 [inlined]\n     [4] (::Base.Threads.var\"#1#2\"{var\"#278#threadsfor_fun#109\"{var\"#278#threadsfor_fun#103#110\"{Dict{Any, Any}, Matrix{Float64}, Dict{Any, Any}, Vector{String}, SubArray{String, 1, Vector{String}, Tuple{Vector{Int64}}, false}, SubArray{BitVector, 1, Vector{BitVector}, Tuple{Vector{Int64}}, false}, UnitRange{Int64}}}, Int64})()\n       @ Base.Threads ./threadingconstructs.jl:30",
     "output_type": "error",
     "traceback": [
      "TaskFailedException\n",
      "\n",
      "    nested task error: MethodError: no method matching getindex(::Dict{Any, Any})\n",
      "    Closest candidates are:\n",
      "      getindex(::Dict{K, V}, !Matched::Any) where {K, V} at dict.jl:496\n",
      "      getindex(::AbstractDict, !Matched::Any) at abstractdict.jl:533\n",
      "      getindex(::AbstractDict, !Matched::Any, !Matched::Any, !Matched::Any...) at abstractdict.jl:543\n",
      "    Stacktrace:\n",
      "     [1] macro expansion\n",
      "       @ ~/Master-Thesis/notebooks/PhaLP_traintest.ipynb:34 [inlined]\n",
      "     [2] (::var\"#278#threadsfor_fun#109\"{var\"#278#threadsfor_fun#103#110\"{Dict{Any, Any}, Matrix{Float64}, Dict{Any, Any}, Vector{String}, SubArray{String, 1, Vector{String}, Tuple{Vector{Int64}}, false}, SubArray{BitVector, 1, Vector{BitVector}, Tuple{Vector{Int64}}, false}, UnitRange{Int64}}})(tid::Int64; onethread::Bool)\n",
      "       @ Main ./threadingconstructs.jl:84\n",
      "     [3] #278#threadsfor_fun\n",
      "       @ ./threadingconstructs.jl:51 [inlined]\n",
      "     [4] (::Base.Threads.var\"#1#2\"{var\"#278#threadsfor_fun#109\"{var\"#278#threadsfor_fun#103#110\"{Dict{Any, Any}, Matrix{Float64}, Dict{Any, Any}, Vector{String}, SubArray{String, 1, Vector{String}, Tuple{Vector{Int64}}, false}, SubArray{BitVector, 1, Vector{BitVector}, Tuple{Vector{Int64}}, false}, UnitRange{Int64}}}, Int64})()\n",
      "       @ Base.Threads ./threadingconstructs.jl:30\n",
      "\n",
      "Stacktrace:\n",
      " [1] wait\n",
      "   @ ./task.jl:345 [inlined]\n",
      " [2] threading_run(fun::var\"#278#threadsfor_fun#109\"{var\"#278#threadsfor_fun#103#110\"{Dict{Any, Any}, Matrix{Float64}, Dict{Any, Any}, Vector{String}, SubArray{String, 1, Vector{String}, Tuple{Vector{Int64}}, false}, SubArray{BitVector, 1, Vector{BitVector}, Tuple{Vector{Int64}}, false}, UnitRange{Int64}}}, static::Bool)\n",
      "   @ Base.Threads ./threadingconstructs.jl:38\n",
      " [3] macro expansion\n",
      "   @ ./threadingconstructs.jl:89 [inlined]\n",
      " [4] simp_test(seq_dict::Dict{Any, Any}, feature_dict::Dict{String, Union{Missing, String}})\n",
      "   @ Main ~/Master-Thesis/notebooks/PhaLP_traintest.ipynb:24\n",
      " [5] top-level scope\n",
      "   @ ~/Master-Thesis/notebooks/PhaLP_traintest.ipynb:1"
     ]
    }
   ],
   "source": [
    "simp_test(phalp_cnn_rand, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "KeyError: key \"UPI001463ABBB\" not found",
     "output_type": "error",
     "traceback": [
      "KeyError: key \"UPI001463ABBB\" not found\n",
      "\n",
      "Stacktrace:\n",
      " [1] getindex(h::Dict{String, Union{Missing, String}}, key::String)\n",
      "   @ Base ./dict.jl:498\n",
      " [2] top-level scope\n",
      "   @ ~/Master-Thesis/notebooks/PhaLP_traintest.ipynb:1"
     ]
    }
   ],
   "source": [
    "new[\"UPI001463ABBB\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
