{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cosine"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "using LinearAlgebra\n",
    "\"\"\"\n",
    "Construct a bipolar vector. By default 10000 elements long.\n",
    "\"\"\"\n",
    "hdv(N::Int=10000) = vec(rand((-1,1), 1, N))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Bundles bipolar hyperdimensional vectors.\n",
    "\"\"\"\n",
    "add(vectors::Vector...) = reduce(.+, vectors) .|> sign\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Binds binpolar hyperdimensional vectors.\n",
    "\"\"\"\n",
    "multiply(vectors::Vector...) = reduce(.*, vectors)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Permutes a bipolar hyperdimensional vector by an adjustable circular shift.\n",
    "\"\"\"\n",
    "perm(vector::Vector, k::Int=1) = circshift(vector, k)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculates the cosine similarity between two bipolar vectors.\n",
    "\"\"\"\n",
    "cosine(x, y) = dot(x, y) / (norm(x) * norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hamming"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Construct a binary vector. By default 10000 elements long.\n",
    "\"\"\"\n",
    "bithdv(N::Int=10000) = bitrand(N)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Bundles binary hyperdimensional vectors based on the element-wise majority rule.\n",
    "\"\"\"\n",
    "function bitadd(vectors::BitVector ...)\n",
    "    v = reduce(.+, vectors)\n",
    "    n = length(vectors) / 2\n",
    "    x = [i > n ? 1 : i < n ? 0 : rand(0:1) for i in v]\n",
    "    return convert(BitVector, x)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Binds binary hyperdimensional vectors based on an element-wise XOR gate.\n",
    "\"\"\"\n",
    "bitbind(vectors::BitVector ...) =  reduce(.⊻, vectors)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Permutes a hyperdimensional vector by an adjustable circular shift.\n",
    "\"\"\"\n",
    "bitperm(vector::BitVector, k::Int=1) = circshift(vector, k)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculates the Hamming distance between two binary vectors.\n",
    "\"\"\"\n",
    "hamming(x::BitVector, y::BitVector) = sum(x .!= y)/length(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 4 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>ID</th><th>sequence</th><th>class</th><th>class_num</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"String\">String</th><th title=\"String31\">String31</th><th title=\"Int64\">Int64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>AAWKWAWAKKWAKAKKWAKAA</td><td>mod. active</td><td>2</td></tr><tr><th>2</th><td>2</td><td>AIGKFLHSAKKFGKAFVGEIMNS</td><td>mod. active</td><td>2</td></tr><tr><th>3</th><td>3</td><td>AWKKWAKAWKWAKAKWWAKAA</td><td>mod. active</td><td>2</td></tr><tr><th>4</th><td>4</td><td>ESFSDWWKLLAE</td><td>mod. active</td><td>2</td></tr><tr><th>5</th><td>5</td><td>ETFADWWKLLAE</td><td>mod. active</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& ID & sequence & class & class\\_num\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & String31 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & AAWKWAWAKKWAKAKKWAKAA & mod. active & 2 \\\\\n",
       "\t2 & 2 & AIGKFLHSAKKFGKAFVGEIMNS & mod. active & 2 \\\\\n",
       "\t3 & 3 & AWKKWAKAWKWAKAKWWAKAA & mod. active & 2 \\\\\n",
       "\t4 & 4 & ESFSDWWKLLAE & mod. active & 2 \\\\\n",
       "\t5 & 5 & ETFADWWKLLAE & mod. active & 2 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m ID    \u001b[0m\u001b[1m sequence                \u001b[0m\u001b[1m class       \u001b[0m\u001b[1m class_num \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String                  \u001b[0m\u001b[90m String31    \u001b[0m\u001b[90m Int64     \u001b[0m\n",
       "─────┼────────────────────────────────────────────────────────\n",
       "   1 │     1  AAWKWAWAKKWAKAKKWAKAA    mod. active          2\n",
       "   2 │     2  AIGKFLHSAKKFGKAFVGEIMNS  mod. active          2\n",
       "   3 │     3  AWKKWAKAWKWAKAKWWAKAA    mod. active          2\n",
       "   4 │     4  ESFSDWWKLLAE             mod. active          2\n",
       "   5 │     5  ETFADWWKLLAE             mod. active          2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, CSV\n",
    "data = CSV.read(\"ProtExdata/ACPs_Breast_cancer.csv\", DataFrame)\n",
    "unique(data.class)\n",
    "class_num = [i == \"very active\" ? 1 : i == \"mod. active\" ? 2 : i == \"inactive - exp\" ? 3 : 4 for i in data.class]\n",
    "data[!, :class_num] = class_num\n",
    "data = data[data.class_num .!= 4, :]\n",
    "first(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Vector{Char}} with 4 entries:\n",
       "  \"non-polar\" => ['G', 'A', 'V', 'C', 'P', 'L', 'I', 'M', 'W', 'F']\n",
       "  \"polar\"     => ['S', 'T', 'Y', 'N', 'Q']\n",
       "  \"pos+\"      => ['L', 'R', 'H']\n",
       "  \"neg-\"      => ['D', 'E']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AA_list = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
    "groups = Dict(\"polar\" => ['S', 'T', 'Y', 'N', 'Q'], \"non-polar\" => ['G', 'A', 'V', 'C', 'P', 'L', 'I', 'M', 'W', 'F'], \n",
    "         \"pos+\" => ['L', 'R', 'H'], \"neg-\" => ['D', 'E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AA_dist_calc (generic function with 2 methods)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_list = [i for (k,v) in groups for i in v]\n",
    "\n",
    "function AA_dist_calc(x, cos=true)\n",
    "    df = DataFrame([[] for i in 1:20], string.(sorted_list), makeunique=true)\n",
    "    for i in sorted_list\n",
    "        r = []\n",
    "        for j in sorted_list\n",
    "            if cos == true\n",
    "                push!(r, cosine(x[i], x[j]))\n",
    "            else\n",
    "                push!(r, hamming(x[i], x[j]))\n",
    "            end\n",
    "        end\n",
    "        push!(df, r)\n",
    "    end\n",
    "    insertcols!(df, 1, :coef => sorted_list)\n",
    "    return df\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mat_scaler (generic function with 2 methods)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function scaler(row, lower, upper)\n",
    "    minx = minimum(row)\n",
    "    maxx = maximum(row)\n",
    "    x = [lower + ((i - minx)*(upper-lower))/(maxx - minx) for i in row]\n",
    "    return x\n",
    "end\n",
    "\n",
    "function mat_scaler(matrix, lower, upper, dim = 1)\n",
    "    if dim == 1\n",
    "        scaled = reduce(hcat, [scaler(matrix[:, i], lower, upper) for i in 1:size(matrix, 2)])\n",
    "    elseif dim == 2\n",
    "        scaled = reduce(hcat, [scaler(matrix[:, i], lower, upper) for i in 1:size(matrix, 1)])\n",
    "    end\n",
    "    return scaled\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Char, Vector{Float32}} with 20 entries:\n",
       "  'M' => [-1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0  …  -1.0, -1.0…\n",
       "  'K' => [-1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0  …  -1.0, -1.0,…\n",
       "  'P' => [1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0  …  1.0, -1.0, …\n",
       "  'Q' => [-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0  …  -1.0, -1.…\n",
       "  'I' => [-1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0  …  -1.0, -1.0,…\n",
       "  'H' => [-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0  …  -1.0, -1.…\n",
       "  'E' => [1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0  …  1.0, -1.0,…\n",
       "  'W' => [-1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0  …  1.0, -1.0…\n",
       "  'S' => [-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0  …  -1.0, -1.…\n",
       "  'T' => [-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0  …  -1.0, -1.…\n",
       "  'C' => [1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0  …  1.0, -1.0, 1…\n",
       "  'D' => [-1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0  …  -1.0, -1.0,…\n",
       "  'A' => [-1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0  …  -1.0, -1.0…\n",
       "  'L' => [-1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0  …  -1.0, 1.…\n",
       "  'Y' => [1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0  …  1.0, -1.0, …\n",
       "  'V' => [1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0  …  -1.0, 1.0, …\n",
       "  'R' => [-1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0  …  1.0, -1.0,…\n",
       "  'G' => [-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0  …  -1.0, -1.0…\n",
       "  'F' => [1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0  …  1.0, -1.0, …\n",
       "  'N' => [-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0  …  -1.0, -1.…"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "using TableTransforms\n",
    "py\"\"\"\n",
    "import pickle\n",
    "infile = open(\"/home/mfat/Unief/Thesis/ThesisFatjanov/data/aa_embeddings\",'rb')\n",
    "embeddings = pickle.load(infile)\n",
    "infile.close()\n",
    "\"\"\"\n",
    "embeddings = PyArray(py\"embeddings\"o)\n",
    "\n",
    "embeddings_hdv = embeddings*random_hdv_bin\n",
    "embeddings_hdv = mat_scaler(embeddings_hdv,-1,1)\n",
    "hdvs = [embeddings_hdv[i, :] for i in 1:20]\n",
    "AA_dict = Dict(zip(AA_list, hdvs))\n",
    "\n",
    "embeddings_hdv_bin = round.(mat_scaler(embeddings*random_hdv_bin, 0, 1))\n",
    "hdvs_bin = [convert(BitVector, embeddings_hdv_bin[i, :]) for i in 1:20]\n",
    "AA_dict_bin = Dict(zip(AA_list, hdvs_bin))\n",
    "\n",
    "embeddings_hdv_bip = mat_scaler(embeddings*random_hdv_bip, -1, 1) .|> sign\n",
    "hdvs_bip = [embeddings_hdv_bip[i, :] for i in 1:20]\n",
    "AA_dict_bip = Dict(zip(AA_list, hdvs_bip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>20 rows × 21 columns (omitted printing of 10 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>coef</th><th>G</th><th>A</th><th>V</th><th>C</th><th>P</th><th>L</th><th>I</th><th>M</th><th>W</th><th>F</th></tr><tr><th></th><th title=\"Char\">Char</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th></tr></thead><tbody><tr><th>1</th><td>G</td><td>0.0</td><td>0.019</td><td>0.8369</td><td>0.6442</td><td>0.2981</td><td>0.7909</td><td>0.0756</td><td>0.1097</td><td>0.2431</td><td>0.4323</td></tr><tr><th>2</th><td>A</td><td>0.019</td><td>0.0</td><td>0.8403</td><td>0.6316</td><td>0.3051</td><td>0.7943</td><td>0.088</td><td>0.1223</td><td>0.2551</td><td>0.4199</td></tr><tr><th>3</th><td>V</td><td>0.8369</td><td>0.8403</td><td>0.0</td><td>0.4959</td><td>0.769</td><td>0.0582</td><td>0.8413</td><td>0.7744</td><td>0.74</td><td>0.7024</td></tr><tr><th>4</th><td>C</td><td>0.6442</td><td>0.6316</td><td>0.4959</td><td>0.0</td><td>0.4093</td><td>0.5415</td><td>0.6284</td><td>0.6775</td><td>0.5181</td><td>0.2183</td></tr><tr><th>5</th><td>P</td><td>0.2981</td><td>0.3051</td><td>0.769</td><td>0.4093</td><td>0.0</td><td>0.7864</td><td>0.2357</td><td>0.2924</td><td>0.1374</td><td>0.2338</td></tr><tr><th>6</th><td>L</td><td>0.7909</td><td>0.7943</td><td>0.0582</td><td>0.5415</td><td>0.7864</td><td>0.0</td><td>0.8025</td><td>0.7286</td><td>0.7284</td><td>0.7434</td></tr><tr><th>7</th><td>I</td><td>0.0756</td><td>0.088</td><td>0.8413</td><td>0.6284</td><td>0.2357</td><td>0.8025</td><td>0.0</td><td>0.0823</td><td>0.1677</td><td>0.4237</td></tr><tr><th>8</th><td>M</td><td>0.1097</td><td>0.1223</td><td>0.7744</td><td>0.6775</td><td>0.2924</td><td>0.7286</td><td>0.0823</td><td>0.0</td><td>0.1882</td><td>0.4882</td></tr><tr><th>9</th><td>W</td><td>0.2431</td><td>0.2551</td><td>0.74</td><td>0.5181</td><td>0.1374</td><td>0.7284</td><td>0.1677</td><td>0.1882</td><td>0.0</td><td>0.3588</td></tr><tr><th>10</th><td>F</td><td>0.4323</td><td>0.4199</td><td>0.7024</td><td>0.2183</td><td>0.2338</td><td>0.7434</td><td>0.4237</td><td>0.4882</td><td>0.3588</td><td>0.0</td></tr><tr><th>11</th><td>S</td><td>0.0394</td><td>0.0464</td><td>0.8045</td><td>0.674</td><td>0.3297</td><td>0.7557</td><td>0.097</td><td>0.0967</td><td>0.2595</td><td>0.4651</td></tr><tr><th>12</th><td>T</td><td>0.0579</td><td>0.0663</td><td>0.7934</td><td>0.6891</td><td>0.333</td><td>0.7418</td><td>0.0973</td><td>0.0806</td><td>0.2518</td><td>0.4814</td></tr><tr><th>13</th><td>Y</td><td>0.5139</td><td>0.4997</td><td>0.6166</td><td>0.1349</td><td>0.3208</td><td>0.6608</td><td>0.5157</td><td>0.5748</td><td>0.4444</td><td>0.0952</td></tr><tr><th>14</th><td>N</td><td>0.0098</td><td>0.0202</td><td>0.8311</td><td>0.6496</td><td>0.3051</td><td>0.7835</td><td>0.0788</td><td>0.1051</td><td>0.2457</td><td>0.4385</td></tr><tr><th>15</th><td>Q</td><td>0.0529</td><td>0.0641</td><td>0.7978</td><td>0.6887</td><td>0.3258</td><td>0.7478</td><td>0.0901</td><td>0.076</td><td>0.2446</td><td>0.4804</td></tr><tr><th>16</th><td>L</td><td>0.7909</td><td>0.7943</td><td>0.0582</td><td>0.5415</td><td>0.7864</td><td>0.0</td><td>0.8025</td><td>0.7286</td><td>0.7284</td><td>0.7434</td></tr><tr><th>17</th><td>R</td><td>0.0993</td><td>0.1083</td><td>0.852</td><td>0.5951</td><td>0.203</td><td>0.8182</td><td>0.0353</td><td>0.1136</td><td>0.1534</td><td>0.3896</td></tr><tr><th>18</th><td>H</td><td>0.0138</td><td>0.0224</td><td>0.8377</td><td>0.6466</td><td>0.2961</td><td>0.7883</td><td>0.0698</td><td>0.1015</td><td>0.2369</td><td>0.4343</td></tr><tr><th>19</th><td>D</td><td>0.0408</td><td>0.056</td><td>0.8431</td><td>0.6504</td><td>0.2689</td><td>0.7995</td><td>0.039</td><td>0.0903</td><td>0.2035</td><td>0.4423</td></tr><tr><th>20</th><td>E</td><td>0.2378</td><td>0.2318</td><td>0.8333</td><td>0.4244</td><td>0.1121</td><td>0.8387</td><td>0.2114</td><td>0.2815</td><td>0.1933</td><td>0.2131</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccccc}\n",
       "\t& coef & G & A & V & C & P & L & I & M & W & F & \\\\\n",
       "\t\\hline\n",
       "\t& Char & Any & Any & Any & Any & Any & Any & Any & Any & Any & Any & \\\\\n",
       "\t\\hline\n",
       "\t1 & G & 0.0 & 0.019 & 0.8369 & 0.6442 & 0.2981 & 0.7909 & 0.0756 & 0.1097 & 0.2431 & 0.4323 & $\\dots$ \\\\\n",
       "\t2 & A & 0.019 & 0.0 & 0.8403 & 0.6316 & 0.3051 & 0.7943 & 0.088 & 0.1223 & 0.2551 & 0.4199 & $\\dots$ \\\\\n",
       "\t3 & V & 0.8369 & 0.8403 & 0.0 & 0.4959 & 0.769 & 0.0582 & 0.8413 & 0.7744 & 0.74 & 0.7024 & $\\dots$ \\\\\n",
       "\t4 & C & 0.6442 & 0.6316 & 0.4959 & 0.0 & 0.4093 & 0.5415 & 0.6284 & 0.6775 & 0.5181 & 0.2183 & $\\dots$ \\\\\n",
       "\t5 & P & 0.2981 & 0.3051 & 0.769 & 0.4093 & 0.0 & 0.7864 & 0.2357 & 0.2924 & 0.1374 & 0.2338 & $\\dots$ \\\\\n",
       "\t6 & L & 0.7909 & 0.7943 & 0.0582 & 0.5415 & 0.7864 & 0.0 & 0.8025 & 0.7286 & 0.7284 & 0.7434 & $\\dots$ \\\\\n",
       "\t7 & I & 0.0756 & 0.088 & 0.8413 & 0.6284 & 0.2357 & 0.8025 & 0.0 & 0.0823 & 0.1677 & 0.4237 & $\\dots$ \\\\\n",
       "\t8 & M & 0.1097 & 0.1223 & 0.7744 & 0.6775 & 0.2924 & 0.7286 & 0.0823 & 0.0 & 0.1882 & 0.4882 & $\\dots$ \\\\\n",
       "\t9 & W & 0.2431 & 0.2551 & 0.74 & 0.5181 & 0.1374 & 0.7284 & 0.1677 & 0.1882 & 0.0 & 0.3588 & $\\dots$ \\\\\n",
       "\t10 & F & 0.4323 & 0.4199 & 0.7024 & 0.2183 & 0.2338 & 0.7434 & 0.4237 & 0.4882 & 0.3588 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & S & 0.0394 & 0.0464 & 0.8045 & 0.674 & 0.3297 & 0.7557 & 0.097 & 0.0967 & 0.2595 & 0.4651 & $\\dots$ \\\\\n",
       "\t12 & T & 0.0579 & 0.0663 & 0.7934 & 0.6891 & 0.333 & 0.7418 & 0.0973 & 0.0806 & 0.2518 & 0.4814 & $\\dots$ \\\\\n",
       "\t13 & Y & 0.5139 & 0.4997 & 0.6166 & 0.1349 & 0.3208 & 0.6608 & 0.5157 & 0.5748 & 0.4444 & 0.0952 & $\\dots$ \\\\\n",
       "\t14 & N & 0.0098 & 0.0202 & 0.8311 & 0.6496 & 0.3051 & 0.7835 & 0.0788 & 0.1051 & 0.2457 & 0.4385 & $\\dots$ \\\\\n",
       "\t15 & Q & 0.0529 & 0.0641 & 0.7978 & 0.6887 & 0.3258 & 0.7478 & 0.0901 & 0.076 & 0.2446 & 0.4804 & $\\dots$ \\\\\n",
       "\t16 & L & 0.7909 & 0.7943 & 0.0582 & 0.5415 & 0.7864 & 0.0 & 0.8025 & 0.7286 & 0.7284 & 0.7434 & $\\dots$ \\\\\n",
       "\t17 & R & 0.0993 & 0.1083 & 0.852 & 0.5951 & 0.203 & 0.8182 & 0.0353 & 0.1136 & 0.1534 & 0.3896 & $\\dots$ \\\\\n",
       "\t18 & H & 0.0138 & 0.0224 & 0.8377 & 0.6466 & 0.2961 & 0.7883 & 0.0698 & 0.1015 & 0.2369 & 0.4343 & $\\dots$ \\\\\n",
       "\t19 & D & 0.0408 & 0.056 & 0.8431 & 0.6504 & 0.2689 & 0.7995 & 0.039 & 0.0903 & 0.2035 & 0.4423 & $\\dots$ \\\\\n",
       "\t20 & E & 0.2378 & 0.2318 & 0.8333 & 0.4244 & 0.1121 & 0.8387 & 0.2114 & 0.2815 & 0.1933 & 0.2131 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m20×21 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m coef \u001b[0m\u001b[1m G      \u001b[0m\u001b[1m A      \u001b[0m\u001b[1m V      \u001b[0m\u001b[1m C      \u001b[0m\u001b[1m P      \u001b[0m\u001b[1m L      \u001b[0m\u001b[1m I      \u001b[0m\u001b[1m M      \u001b[0m\u001b[1m W\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Char \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m A\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ G     0.0     0.019   0.8369  0.6442  0.2981  0.7909  0.0756  0.1097  0 ⋯\n",
       "   2 │ A     0.019   0.0     0.8403  0.6316  0.3051  0.7943  0.088   0.1223  0\n",
       "   3 │ V     0.8369  0.8403  0.0     0.4959  0.769   0.0582  0.8413  0.7744  0\n",
       "   4 │ C     0.6442  0.6316  0.4959  0.0     0.4093  0.5415  0.6284  0.6775  0\n",
       "   5 │ P     0.2981  0.3051  0.769   0.4093  0.0     0.7864  0.2357  0.2924  0 ⋯\n",
       "   6 │ L     0.7909  0.7943  0.0582  0.5415  0.7864  0.0     0.8025  0.7286  0\n",
       "   7 │ I     0.0756  0.088   0.8413  0.6284  0.2357  0.8025  0.0     0.0823  0\n",
       "   8 │ M     0.1097  0.1223  0.7744  0.6775  0.2924  0.7286  0.0823  0.0     0\n",
       "   9 │ W     0.2431  0.2551  0.74    0.5181  0.1374  0.7284  0.1677  0.1882  0 ⋯\n",
       "  10 │ F     0.4323  0.4199  0.7024  0.2183  0.2338  0.7434  0.4237  0.4882  0\n",
       "  11 │ S     0.0394  0.0464  0.8045  0.674   0.3297  0.7557  0.097   0.0967  0\n",
       "  12 │ T     0.0579  0.0663  0.7934  0.6891  0.333   0.7418  0.0973  0.0806  0\n",
       "  13 │ Y     0.5139  0.4997  0.6166  0.1349  0.3208  0.6608  0.5157  0.5748  0 ⋯\n",
       "  14 │ N     0.0098  0.0202  0.8311  0.6496  0.3051  0.7835  0.0788  0.1051  0\n",
       "  15 │ Q     0.0529  0.0641  0.7978  0.6887  0.3258  0.7478  0.0901  0.076   0\n",
       "  16 │ L     0.7909  0.7943  0.0582  0.5415  0.7864  0.0     0.8025  0.7286  0\n",
       "  17 │ R     0.0993  0.1083  0.852   0.5951  0.203   0.8182  0.0353  0.1136  0 ⋯\n",
       "  18 │ H     0.0138  0.0224  0.8377  0.6466  0.2961  0.7883  0.0698  0.1015  0\n",
       "  19 │ D     0.0408  0.056   0.8431  0.6504  0.2689  0.7995  0.039   0.0903  0\n",
       "  20 │ E     0.2378  0.2318  0.8333  0.4244  0.1121  0.8387  0.2114  0.2815  0\n",
       "\u001b[36m                                                              12 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = AA_dist_calc(AA_dict)\n",
    "df_bip = AA_dist_calc(AA_dict_bip)\n",
    "df_bin = AA_dist_calc(AA_dict_bin, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, BitVector} with 8000 entries:\n",
       "  \"DRR\" => [1, 1, 1, 1, 1, 0, 0, 1, 1, 1  …  1, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n",
       "  \"HTY\" => [1, 1, 0, 0, 1, 1, 1, 1, 1, 1  …  0, 0, 0, 1, 1, 1, 1, 1, 0, 0]\n",
       "  \"QAM\" => [0, 0, 1, 0, 0, 0, 0, 1, 1, 1  …  1, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
       "  \"WMA\" => [0, 1, 0, 1, 0, 0, 0, 1, 1, 0  …  1, 1, 1, 0, 1, 0, 1, 1, 0, 1]\n",
       "  \"PPV\" => [0, 0, 1, 1, 0, 1, 1, 0, 0, 1  …  1, 1, 0, 1, 1, 0, 0, 0, 1, 0]\n",
       "  \"WNG\" => [1, 1, 0, 1, 0, 0, 0, 1, 1, 0  …  1, 1, 1, 1, 1, 0, 1, 1, 0, 0]\n",
       "  \"MSW\" => [1, 0, 1, 0, 1, 1, 0, 1, 1, 1  …  0, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n",
       "  \"TKL\" => [1, 0, 0, 1, 1, 0, 1, 0, 0, 0  …  0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
       "  \"ETI\" => [1, 1, 0, 1, 0, 0, 0, 1, 1, 0  …  1, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n",
       "  \"KLF\" => [0, 0, 0, 1, 1, 0, 0, 0, 0, 0  …  0, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n",
       "  \"AGI\" => [1, 1, 1, 0, 0, 0, 0, 1, 1, 1  …  1, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
       "  \"NMD\" => [0, 1, 1, 0, 0, 0, 0, 1, 1, 1  …  1, 1, 0, 1, 1, 0, 1, 1, 0, 0]\n",
       "  \"YMQ\" => [0, 1, 0, 1, 1, 0, 0, 1, 1, 0  …  1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
       "  \"ETP\" => [1, 1, 0, 1, 1, 1, 0, 1, 1, 0  …  0, 0, 1, 1, 0, 1, 1, 1, 0, 0]\n",
       "  \"FMK\" => [1, 0, 0, 1, 1, 0, 0, 1, 1, 0  …  1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
       "  \"IMW\" => [0, 0, 1, 0, 1, 1, 0, 1, 1, 1  …  0, 1, 1, 1, 0, 1, 1, 1, 0, 0]\n",
       "  \"PRD\" => [1, 1, 0, 0, 0, 0, 0, 1, 1, 0  …  1, 1, 1, 0, 1, 0, 1, 1, 0, 1]\n",
       "  \"PTK\" => [0, 0, 0, 1, 0, 0, 0, 1, 1, 0  …  1, 1, 1, 1, 1, 0, 1, 1, 0, 0]\n",
       "  \"QPE\" => [1, 1, 1, 1, 0, 1, 0, 1, 1, 1  …  1, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
       "  \"YDE\" => [0, 1, 0, 1, 0, 1, 0, 1, 1, 0  …  0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n",
       "  \"KIW\" => [1, 0, 1, 0, 1, 1, 0, 1, 1, 1  …  0, 1, 0, 1, 0, 1, 1, 1, 1, 0]\n",
       "  \"YVC\" => [1, 1, 0, 0, 1, 0, 0, 0, 0, 1  …  0, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n",
       "  \"NLG\" => [0, 0, 0, 1, 0, 1, 1, 0, 0, 0  …  1, 0, 0, 1, 1, 1, 0, 0, 1, 0]\n",
       "  \"YWG\" => [1, 1, 0, 0, 0, 0, 0, 1, 1, 0  …  1, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
       "  \"EFK\" => [0, 0, 0, 0, 1, 1, 0, 1, 1, 0  …  0, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n",
       "  ⋮     => ⋮"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimer_hdvs = Dict(aa1 * aa2 * aa3 => \n",
    "multiply(AA_dict[aa1], perm(AA_dict[aa2]), perm(AA_dict[aa3], 2)) \n",
    "for aa1 in AA_list for aa2 in AA_list for aa3 in AA_list)\n",
    "\n",
    "trimer_hdvs_bip = Dict(aa1 * aa2 * aa3 => \n",
    "multiply(AA_dict_bip[aa1], perm(AA_dict_bip[aa2]), perm(AA_dict_bip[aa3], 2)) \n",
    "for aa1 in AA_list for aa2 in AA_list for aa3 in AA_list)\n",
    "\n",
    "trimer_hdvs_bin = Dict(aa1 * aa2 * aa3 => \n",
    "bitbind(AA_dict_bin[aa1], bitperm(AA_dict_bin[aa2]), bitperm(AA_dict_bin[aa3], 2)) \n",
    "for aa1 in AA_list for aa2 in AA_list for aa3 in AA_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197-element Vector{BitVector}:\n",
       " [0, 0, 1, 1, 1, 0, 0, 1, 1, 1  …  1, 1, 0, 1, 0, 0, 1, 1, 0, 0]\n",
       " [0, 0, 1, 0, 0, 0, 0, 1, 1, 1  …  1, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
       " [0, 0, 1, 1, 0, 0, 0, 1, 1, 1  …  1, 1, 0, 1, 1, 0, 1, 1, 0, 0]\n",
       " [1, 1, 1, 0, 1, 0, 0, 1, 1, 1  …  0, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n",
       " [1, 1, 1, 1, 1, 0, 0, 1, 1, 1  …  0, 0, 1, 1, 0, 0, 1, 1, 0, 0]\n",
       " [1, 0, 1, 0, 1, 0, 0, 1, 1, 1  …  0, 0, 1, 0, 0, 0, 1, 1, 0, 0]\n",
       " [1, 0, 0, 1, 1, 0, 1, 0, 0, 0  …  0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 1, 1, 0, 1, 0, 0, 0  …  0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
       " [0, 1, 0, 0, 1, 1, 1, 0, 0, 0  …  1, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n",
       " [0, 1, 1, 0, 0, 0, 0, 1, 1, 1  …  1, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
       " [0, 0, 0, 1, 1, 0, 1, 0, 0, 0  …  1, 1, 1, 0, 0, 0, 0, 0, 1, 1]\n",
       " [1, 1, 1, 1, 1, 1, 0, 1, 1, 1  …  0, 1, 0, 0, 1, 0, 1, 1, 0, 1]\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0  …  1, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
       " ⋮\n",
       " [1, 1, 0, 1, 1, 1, 1, 0, 0, 0  …  0, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
       " [1, 1, 0, 1, 1, 1, 1, 0, 0, 0  …  0, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
       " [0, 1, 0, 1, 0, 1, 1, 0, 0, 0  …  1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
       " [1, 1, 0, 1, 0, 1, 1, 0, 0, 0  …  1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
       " [1, 0, 0, 1, 0, 1, 1, 0, 0, 0  …  1, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n",
       " [0, 0, 0, 0, 0, 1, 1, 1, 1, 0  …  0, 0, 1, 0, 1, 1, 1, 1, 0, 0]\n",
       " [0, 0, 1, 1, 0, 1, 1, 0, 0, 1  …  1, 1, 0, 1, 1, 1, 0, 0, 1, 1]\n",
       " [0, 0, 1, 0, 1, 1, 0, 1, 1, 1  …  1, 1, 0, 0, 1, 1, 1, 1, 0, 0]\n",
       " [0, 1, 1, 0, 1, 1, 0, 1, 1, 1  …  0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n",
       " [0, 1, 1, 0, 0, 1, 0, 1, 1, 1  …  1, 1, 0, 0, 1, 1, 1, 1, 1, 1]\n",
       " [0, 1, 1, 0, 1, 1, 0, 1, 1, 1  …  0, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
       " [0, 0, 1, 0, 1, 1, 1, 1, 1, 1  …  1, 1, 0, 0, 1, 1, 1, 1, 1, 0]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function embedder(sequence, c)\n",
    "    if c == 1\n",
    "        l = [trimer_hdvs[sequence[i:i+2]] for i in 1:length(sequence)-2]\n",
    "        v = add(hcat(l)...)\n",
    "        return v\n",
    "    elseif c == 2\n",
    "        l = [trimer_hdvs_bip[sequence[i:i+2]] for i in 1:length(sequence)-2]\n",
    "        v = add(hcat(l)...)\n",
    "        return v\n",
    "    elseif c == 3\n",
    "        l = [trimer_hdvs_bin[sequence[i:i+2]] for i in 1:length(sequence)-2]\n",
    "        v = bitadd(hcat(l)...)\n",
    "        return v\n",
    "    end\n",
    "end\n",
    "\n",
    "l = []\n",
    "for i in data.sequence\n",
    "    push!(l, embedder(i, 1))\n",
    "end\n",
    "data[!, :hdv_r] = l\n",
    "\n",
    "l = []\n",
    "for i in data.sequence\n",
    "    push!(l, embedder(i, 2))\n",
    "end\n",
    "data[!, :hdv_bip] = l\n",
    "\n",
    "l = BitVector[]\n",
    "for i in data.sequence\n",
    "    push!(l, embedder(i, 3))\n",
    "end\n",
    "data[!, :hdv_bin] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000-element BitVector:\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " ⋮\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_hdv = add(hcat([i for i in data[data.class_num .== 1, :hdv_r]])...)\n",
    "modactive_hdv = add(hcat([i for i in data[data.class_num .== 2, :hdv_r]])...)\n",
    "notactive_exp_hdv = add(hcat([i for i in data[data.class_num .== 3, :hdv_r]])...)\n",
    "\n",
    "active_hdv_bip = add(hcat([i for i in data[data.class_num .== 1, :hdv_bip]])...)\n",
    "modactive_hdv_bip = add(hcat([i for i in data[data.class_num .== 2, :hdv_bip]])...)\n",
    "notactive_exp_hdv_bip = add(hcat([i for i in data[data.class_num .== 3, :hdv_bip]])...)\n",
    "\n",
    "active_hdv_bin = bitadd(hcat([i for i in data[data.class_num .== 1, :hdv_bin]])...)\n",
    "modactive_hdv_bin = bitadd(hcat([i for i in data[data.class_num .== 2, :hdv_bin]])...)\n",
    "notactive_exp_hdv_bin = bitadd(hcat([i for i in data[data.class_num .== 3, :hdv_bin]])...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000-element Vector{Float32}:\n",
       "  1.0\n",
       " -1.0\n",
       "  1.0\n",
       " -1.0\n",
       "  1.0\n",
       " -1.0\n",
       " -1.0\n",
       "  1.0\n",
       "  1.0\n",
       "  1.0\n",
       "  1.0\n",
       " -1.0\n",
       "  1.0\n",
       "  ⋮\n",
       " -1.0\n",
       "  1.0\n",
       "  1.0\n",
       " -1.0\n",
       "  1.0\n",
       "  1.0\n",
       "  1.0\n",
       "  1.0\n",
       "  1.0\n",
       " -1.0\n",
       "  1.0\n",
       "  1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = nrow(data)\n",
    "\n",
    "train = rand(n) .< 0.8\n",
    "test = train = .! train\n",
    "\n",
    "train_df = data[[i for i in 1:n if train[i] == 1], :]\n",
    "test_df = data[[i for i in 1:n if test[i] == 1], :]\n",
    "\n",
    "active_hdv_t_bin = bitadd(hcat([i for i in train_df[train_df.class_num .== 1, :hdv_bin]])...)\n",
    "modactive_hdv_t_bin = bitadd(hcat([i for i in train_df[train_df.class_num .== 2, :hdv_bin]])...)\n",
    "notactive_exp_hdv_t_bin = bitadd(hcat([i for i in train_df[train_df.class_num .== 3, :hdv_bin]])...)\n",
    "\n",
    "active_hdv_t = add(hcat([i for i in train_df[train_df.class_num .== 1, :hdv_r]])...)\n",
    "modactive_hdv_t = add(hcat([i for i in train_df[train_df.class_num .== 2, :hdv_r]])...)\n",
    "notactive_exp_hdv_t = add(hcat([i for i in train_df[train_df.class_num .== 3, :hdv_r]])...)\n",
    "\n",
    "active_hdv_t_bip = add(hcat([i for i in train_df[train_df.class_num .== 1, :hdv_bip]])...)\n",
    "modactive_hdv_t_bip  = add(hcat([i for i in train_df[train_df.class_num .== 2, :hdv_bip]])...)\n",
    "notactive_exp_hdv_t_bip  = add(hcat([i for i in train_df[train_df.class_num .== 3, :hdv_bip]])...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(seq, c)\n",
    "    if c == 1\n",
    "        y = [cosine(active_hdv_t, seq), cosine(modactive_hdv_t, seq), cosine(notactive_exp_hdv_t, seq)]\n",
    "        return findmin(y)[2]\n",
    "    elseif c == 3\n",
    "        y = [hamming(active_hdv_t_bin, seq), hamming(modactive_hdv_t_bin, seq), hamming(notactive_exp_hdv_t_bin, seq)]\n",
    "        return findmin(y)[2]\n",
    "    elseif c == 2\n",
    "        y = [cosine(active_hdv_t_bip, seq), cosine(modactive_hdv_t_bip, seq), cosine(notactive_exp_hdv_t_bip, seq)]\n",
    "        return findmin(y)[2]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07317073170731707\n",
      "0.07317073170731707\n",
      "0.5365853658536586\n"
     ]
    }
   ],
   "source": [
    "using StatsBase\n",
    "pred = [predict(i, 1) for i in test_df.hdv_r]\n",
    "println(mean(test_df.class_num .== pred))\n",
    "\n",
    "pred = [predict(i, 2) for i in test_df.hdv_bip]\n",
    "println(mean(test_df.class_num .== pred))\n",
    "\n",
    "pred = [predict(i, 3) for i in test_df.hdv_bin]\n",
    "println(mean(test_df.class_num .== pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convolved_embedding (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function convolved_embedding(sequence, tokens, k=3)\n",
    "    \"\"\"\n",
    "    Simple 2-layer convolved embedding in hyperdimensional space\n",
    "    \"\"\"\n",
    "    # layer 1\n",
    "    kmer_hdvs = []\n",
    "    for i in 1:length(sequence)-k+1\n",
    "        kmer = sequence[i:i+k-1]\n",
    "        aa_hdvs = [circshift(tokens[aa], k-l) for (l, aa) in enumerate(kmer)]\n",
    "        push!(kmer_hdvs, bitbind(aa_hdvs))\n",
    "    end\n",
    "    \n",
    "    # layer 2\n",
    "    conv_kmer_hdvs = []\n",
    "    for i in 1:length(kmer_hdvs)-k+1\n",
    "        convolved_kmers = kmer_hdvs[i:i+k-1]\n",
    "        conv_hdvs = [circshift(convolved_kmers[l], k-l) for (l, km) in enumerate(convolved_kmers)]\n",
    "        push!(conv_kmer_hdvs, bitbind(conv_hdvs))\n",
    "    end\n",
    "    \n",
    "    return bitadd(conv_kmer_hdvs)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
