{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(10000 => 100),                  \u001b[90m# 1_000_100 parameters\u001b[39m\n",
       "  binarize,\n",
       "  Dense(100 => 10),                     \u001b[90m# 1_010 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m1_001_110 parameters, 3.819 MiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Flux\n",
    "\n",
    "# Define the binarize function\n",
    "binarize(x) = x .> 0.5\n",
    "\n",
    "# Define the model architecture\n",
    "model = Chain(\n",
    "  Dense(10000, 100),\n",
    "  binarize,\n",
    "  Dense(100, 10),\n",
    "  softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss(x, y) = Flux.crossentropy(model(x), y)\n",
    "optim = ADAM()\n",
    "\n",
    "# Generate some dummy data for testing\n",
    "x = rand((0,1), 10000)\n",
    "y = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "# Train the model\n",
    "for i = 1:1000\n",
    "  Flux.train!(loss, Flux.params(model), [(x, y)], optim)\n",
    "end\n",
    "\n",
    "# Test the model\n",
    "test_x = rand(Float32, 10000)\n",
    "prediction = argmax(model(test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching *(::String1, ::Float32)\nClosest candidates are:\n  *(::Any, ::Any, !Matched::Any, !Matched::Any...) at operators.jl:591\n  *(!Matched::T, ::T) where T<:Union{Float16, Float32, Float64} at float.jl:385\n  *(::Union{AbstractChar, AbstractString}, !Matched::Union{AbstractChar, AbstractString}...) at strings/basic.jl:260\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching *(::String1, ::Float32)\n",
      "Closest candidates are:\n",
      "  *(::Any, ::Any, !Matched::Any, !Matched::Any...) at operators.jl:591\n",
      "  *(!Matched::T, ::T) where T<:Union{Float16, Float32, Float64} at float.jl:385\n",
      "  *(::Union{AbstractChar, AbstractString}, !Matched::Union{AbstractChar, AbstractString}...) at strings/basic.jl:260\n",
      "  ...\n",
      "\n",
      "Stacktrace:\n",
      "  [1] macro expansion\n",
      "    @ ~/.julia/packages/Zygote/TSj5C/src/compiler/interface2.jl:0 [inlined]\n",
      "  [2] _pullback(::Zygote.Context{true}, ::typeof(*), ::String1, ::Float32)\n",
      "    @ Zygote ~/.julia/packages/Zygote/TSj5C/src/compiler/interface2.jl:9\n",
      "  [3] _pullback\n",
      "    @ ~/.julia/packages/Flux/Nzh8J/src/losses/utils.jl:17 [inlined]\n",
      "  [4] _pullback(::Zygote.Context{true}, ::typeof(Flux.Losses.xlogy), ::String1, ::Float32)\n",
      "    @ Zygote ~/.julia/packages/Zygote/TSj5C/src/compiler/interface2.jl:0\n",
      "  [5] (::Zygote.var\"#860#865\"{Zygote.Context{true}, typeof(Flux.Losses.xlogy)})(::String1, ::Vararg{Any})\n",
      "    @ Zygote ~/.julia/packages/Zygote/TSj5C/src/lib/broadcast.jl:206\n",
      "  [6] _broadcast_getindex_evalf\n",
      "    @ ./broadcast.jl:670 [inlined]\n",
      "  [7] _broadcast_getindex\n",
      "    @ ./broadcast.jl:643 [inlined]\n",
      "  [8] getindex\n",
      "    @ ./broadcast.jl:597 [inlined]\n",
      "  [9] copy\n",
      "    @ ./broadcast.jl:899 [inlined]\n",
      " [10] materialize\n",
      "    @ ./broadcast.jl:860 [inlined]\n",
      " [11] _broadcast\n",
      "    @ ~/.julia/packages/Zygote/TSj5C/src/lib/broadcast.jl:181 [inlined]\n",
      " [12] adjoint\n",
      "    @ ~/.julia/packages/Zygote/TSj5C/src/lib/broadcast.jl:206 [inlined]\n",
      " [13] _pullback\n",
      "    @ ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:65 [inlined]\n",
      " [14] _apply\n",
      "    @ ./boot.jl:816 [inlined]\n",
      " [15] adjoint\n",
      "    @ ~/.julia/packages/Zygote/TSj5C/src/lib/lib.jl:203 [inlined]\n",
      " [16] _pullback\n",
      "    @ ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:65 [inlined]\n",
      " [17] _pullback\n",
      "    @ ./broadcast.jl:1304 [inlined]\n",
      " [18] _pullback\n",
      "    @ ~/.julia/packages/Flux/Nzh8J/src/losses/functions.jl:227 [inlined]\n",
      " [19] _pullback(::Zygote.Context{true}, ::Flux.Losses.var\"##crossentropy#14\", ::Int64, ::typeof(Statistics.mean), ::Float32, ::typeof(Flux.Losses.crossentropy), ::Vector{Float32}, ::String1)\n",
      "    @ Zygote ~/.julia/packages/Zygote/TSj5C/src/compiler/interface2.jl:0\n",
      " [20] _pullback\n",
      "    @ ~/.julia/packages/Flux/Nzh8J/src/losses/functions.jl:225 [inlined]\n",
      " [21] _pullback(::Zygote.Context{true}, ::typeof(Flux.Losses.crossentropy), ::Vector{Float32}, ::String1)\n",
      "    @ Zygote ~/.julia/packages/Zygote/TSj5C/src/compiler/interface2.jl:0\n",
      " [22] _pullback\n",
      "    @ ~/Master-Thesis/notebooks/BNN.ipynb:19 [inlined]\n",
      " [23] _pullback(::Zygote.Context{true}, ::typeof(loss), ::Vector{Float64}, ::String1)\n",
      "    @ Zygote ~/.julia/packages/Zygote/TSj5C/src/compiler/interface2.jl:0\n",
      " [24] _apply\n",
      "    @ ./boot.jl:816 [inlined]\n",
      " [25] adjoint\n",
      "    @ ~/.julia/packages/Zygote/TSj5C/src/lib/lib.jl:203 [inlined]\n",
      " [26] _pullback\n",
      "    @ ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:65 [inlined]\n",
      " [27] _pullback\n",
      "    @ ~/.julia/packages/Flux/Nzh8J/src/optimise/train.jl:143 [inlined]\n",
      " [28] _pullback(::Zygote.Context{true}, ::Flux.Optimise.var\"#37#40\"{typeof(loss), Tuple{Vector{Float64}, String1}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/TSj5C/src/compiler/interface2.jl:0\n",
      " [29] pullback(f::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/TSj5C/src/compiler/interface.jl:384\n",
      " [30] withgradient(f::Function, args::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/TSj5C/src/compiler/interface.jl:132\n",
      " [31] macro expansion\n",
      "    @ ~/.julia/packages/Flux/Nzh8J/src/optimise/train.jl:142 [inlined]\n",
      " [32] macro expansion\n",
      "    @ ~/.julia/packages/ProgressLogging/6KXlp/src/ProgressLogging.jl:328 [inlined]\n",
      " [33] train!(loss::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}}, data::Vector{Tuple{Vector{Float64}, String1}}, opt::Adam; cb::Flux.Optimise.var\"#38#41\")\n",
      "    @ Flux.Optimise ~/.julia/packages/Flux/Nzh8J/src/optimise/train.jl:140\n",
      " [34] train!(loss::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}}, data::Vector{Tuple{Vector{Float64}, String1}}, opt::Adam)\n",
      "    @ Flux.Optimise ~/.julia/packages/Flux/Nzh8J/src/optimise/train.jl:136\n",
      " [35] top-level scope\n",
      "    @ ~/Master-Thesis/notebooks/BNN.ipynb:25"
     ]
    }
   ],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "include(\"../src/HDC.jl\")\n",
    "include(\"../src/math.jl\")\n",
    "include(\"../src/experimental.jl\")\n",
    "#Load embeddings from last hidden layer of ESM-2 model (21x1280)\n",
    "aa_embeddings = DataFrame(CSV.File(\"../data/amino_acid_embeddings.csv\"))\n",
    "amino_acids_esm = aa_embeddings.protein_ID\n",
    "aa_emb = Matrix(aa_embeddings[:, 2:end])\n",
    "\n",
    "HDV_mat_bit = nested_arrays2mat([bithdv() for i in 1:size(aa_emb)[2]], true)\n",
    "AA_bit_esm = permutedims(mat_scaler(aa_emb * HDV_mat_bit, 0, 1, 2) .|> round)\n",
    "\n",
    "x = [AA_bit_esm[:, i] for i in 1:21]\n",
    "y = amino_acids_esm\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss(x, y) = Flux.crossentropy(model(x), y)\n",
    "optim = ADAM()\n",
    "\n",
    "# Train the model\n",
    "for i = 1:1000\n",
    "    for i in 1:21\n",
    "        Flux.train!(loss, Flux.params(model), [(x[i], y[i])], optim)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Test the model\n",
    "test_x = amino_acids_esm\n",
    "prediction = argmax(model(test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
