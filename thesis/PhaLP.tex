\chapter{Case study:\\PhaLP dataset}
To implement and evaluate hyperdimensional computing in real-life problems, the potential of hyperdimensional computing will be evaluated on the PhaLP dataset~\cite{phalp} for this chapter. PhaLP is a comprehensive database currently comprising more than 17000 entries of phage lytic proteins including much of their information such as their type, domains and tertiary structures. Phage lytic proteins are used by bacteriophages to infect bacterial cells. To cross the bacterial cell walls, phages use two different types of phage lytic proteins: virion-associated lysins (VALs) and endolysins. Phage lytic proteins also comprise one or more functional domains categorized into two classes: enzymatically active domains (EADs) and cell wall binding domains (CBDs).

All 17356 unique protein sequences were embedded into hyperdimensional vectors. This took only a few minutes for every method on a consumer laptop.

\section{Type classifcation}
Only a fraction of the database is manually annotated to include the protein's type because the amount of phage lytic proteins whose type is described in the literature is relatively small. The developers of PhaLP resorted to a machine learning approach for the classification of unannotated sequences. They embedded each protein sequence \textit{via} SeqVec~\cite{seqvec} and trained a random forest classifier with 100 estimators and balanced weights to classify the proteins whose types were unknown. For this case study, we attempted to simulate their experiments of classifying the proteins into types based on their sequence using several methods. As of March 2023, the latest version of the PhaLP database,~\textit{v2021\_04}, has been used to test our models.
\subsection*{Embedding of sequences into hyperdimensional vectors}
First, we used several sequence encoding techniques tested on several kinds of base vectors. In chapter~\ref{ssec:protclas}, a method of embedding sequences of amino acids has already been discussed. Here, a sequence of amino acids is considered to be a bag of k-mers. Within a k-mer, the amino acids (presented as randomly generated hyperdimensional vectors) are bonded together with sequential information included. All possible k-mers are all then bundled together, the result is then a hyperdimensional vector representing the whole sequence. We also introduce a novel sequence embedding method within the framework of hyperdimensional computing. It is similar to the bag-of-words method in the sense that it bundles vectors of k-mers, but here, the k-mer's positional information will be encoded into the k-mer before bundling. Insert figure The resulting sequences are then visually assessed \textit{via} PCA.

There was no visual difference between the PCA plots for the bag-of-words method and the convolutional method, but there is a clear difference between the different starting embeddings. The sequence embeddings from both the bag-of-words method and the convolutional method made with ESM AA embeddings seem to capture more of the variance between the sequences. To demonstrate hyperdimensional computing as an option for machine learning applications, several methods using this framework have been developed and tested. Out of the 11549 unambiguous UniParc accessions in the newest version of the database, 4829 are manually annotated on their type. Out of these manually annotated proteins, 2803 are endolysins and 2026 are VALs.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.5]{phalp_bow_rand}
    \caption{Scatter-plot of the first two principal components of the encoded phage lytic proteins. The sequences were encoded via the bag-of-words method starting from random hyperdimensional vectors. Only manually annotated phage lytic proteins were considered and are color-coded based on their type. These PCs account for roughly 7 \% of the total variance in the system.}
    \label{fig:phalpbowrand}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.5]{phalp_bow_esm}
    \caption{Scatter-plot of the first two principal components the encoded phage lytic protein. The sequences were encoded via the bag-of-words method starting from hyperdimensionally-extended ESM embeddings. Only manually annotated phage lytic proteins were considered and are color-coded based on their type. These PCs account for roughly 15.5 \% of the total variance in the system.}
    \label{fig:phalpbowesm}
\end{figure}

\subsection*{Naive hyperdimensional addition}\label{ssec:purehdc}
As a baseline level, we use the rudimentary HDV classification technique as seen in chapter~\ref{sec:example}: the HDVs of sequences of the same class are bundled to construct single HDVs representative of every class. Then, a sequence's class is inferred by comparing the sequence's HDV to both class HDV \textit{via} a similarity measure based on the assumption that the class vector is maximally similar to its components. This model was evaluated \textit{via} a stratified 10-fold cross validation.
\begin{table}[h]
    \caption{\label{tab:phalpclass}Results of type classifications using the principal classification technique of hyperdimensional computing and an XGBoost classifier with several kinds of embeddings}
    \resizebox{\textwidth}{!}{\begin{tabular}{|c||c|c|c|c|}
        \hline
        \underline{F1-scores} & \textbf{BoW/random} & \textbf{BoW/ESM} & \textbf{Convolutional/random} & \textbf{Convolutional/ESM} \\
        \hline
        \textbf{Naive addition} & 0.1458 & 0.1468 & 0.1461 & 0.1461 \\
        \hline
        \textbf{XGBoost classifier} & 0.9667 & 0.9754 & 0.9661 & 0.986 \\
        \hline
    \end{tabular}}
\end{table}

It is feasible to learn the classes of every sequence using only operations within the hyperdimensional computing framework. This is done by using the same techniques as in chapter~\ref{sec:example}. Evaluating our model using stratified 10-fold cross-validation results in F1-scores of around 0.14 for every kind of hyperdimensional embedding. This low result is likely due to the possibility of oversaturation of the class vectors.

We can predict the angle between a class vector and a randomly selected vector from said class by $\Theta = \arccos({2k \choose k}/2^{2k})$ with $2k+1$ equal to the number of sequences in the class~\cite{sathdv}. This approximation is valid for bipolar vectors in hyperdimensions $(\ge 10000)$. This equation also suggests that an increase in dimensions will not influence the angle. Evaluating this equation by considering random 1001 vectors in a class, so $k = 500$, results in an angle of $88.6^{\circ}$. This indicates that a vector has a limited capacity: the more vectors we bundle together, the closer the angle will be to $90^{\circ}$ and thus the more dissimilar the class vector becomes to its components. This results in the class vectors not being representative anymore of a given dataset. This equation assumes that the class vector is a bundle of purely random vectors which is not the case for our embeddings; however, it provides us a rough idea about the bundling capacity of a hyperdimensional vector. Thus, using the rudimentary model works only for very small datasets, as seen in the examples in chapter~\ref{sec:example}. So to encode larger datasets, the training algorithm has to be more refined.

\subsection*{Machine learning models with binary hyperdimensional embeddings}
The baseline hyperdimensional classification model has been compared to a more established model, the XGBoost classifier. The classification with an XGBoost classifier is done via the default XGBoost classifier from \textit{XGBoost.jl v2.2.5} and is evaluated \textit{via} \textit{MLJ.jl v0.19.5} with also a stratified 10-fold cross validation. The results with this model for every embedding (provided in table~\ref{tab:phalpclass}) are much more comparable to the results of the experiment in the PhaLP paper. This is an indication that hyperdimensional computing can provide a very fast and reliable method of embedding protein sequences, even without prior biological information. 

The drawback of this machine learning model, which is to be expected from every gradient-based model, is that training and predictions take much longer to compute compared to hyperdimensional training models. The cross validation procedure took up to 5 minutes on a consumer-grade laptop, whilst with the naive additive approach, the procedure took less than 10 seconds to finish.

\subsection*{OnlineHD implementation}
As an answer for the unsatisfactory results of the rudimentary additive approach in part~\ref{ssec:purehdc}, another hyperdimensional computing approach has been assessed for our use case. OnlineHD by A. Hernandez-Cano~\textit{et al.}~\cite{onlinehd} is an algorithm that expands on the classical hyperdimensional training methods by trying to eliminate model saturation. Instead of naively bundling vectors on top of each other, this algorithm assigns weights to every addition  depending on how much new information it adds to the model to prevent class vector saturation.

To train the model, assume a new data point $\vec{V}$ with label $l$ and class vectors $\vec{C_{i}}$ with each having a label $i$. The cosine similarity of $\vec{V}$ with every class vector is then calculated as $cos_{i}$. If $\vec{V}$ with an actual label $l$ would have been predicted as $l'$, the class vectors will be updated as followed (with learning rate $\eta$):

\begin{alignat}{1}
    \label{eqn:onlinehd}
    \vec{C_{l}} &\leftarrow \vec{C_{l}} + \eta (1 - cos_{l}) * \vec{V} \\
    \vec{C_{l'}} &\leftarrow \vec{C_{l'}} - \eta (1 - cos_{l'}) * \vec{V}
\end{alignat}

This means that if a new data point is highly dissimilar to its class vector and thus contains a high amount of new information, the weight of the update will increase. The information is then also subtracted from the incorrectly predicted class vector. If a label would be correctly predicted for a new data point, the model will not be updated to avoid saturation. To initialize the model, the first vector of a class to be assessed is assumed to be the class vector. Due to the nature of this model, we cannot constrict our hyperdimensional embeddings to a bipolar or binary nature anymore and the embeddings are then allowed to be real-numbered. Mathematical operations such as multiplications and additions are then assumed to be element-wise.

On top of single-pass model as discussed above, A. Hernandez-Cano~\textit{et al.} also implemented an iterative retraining algorithm to increase the accuracy of OnlineHD. This starts from the class vectors made \textit{via} the single-pass OnlineHD model, but assesses the class vectors by performing inference with every training vector. If a training vector's label is wrongly predicted, equations 4.1 and 4.2 are then used to update the model. This all is then iterated for a given amount of cycles.

To test these algorithms, real-numbered embeddings have to be made from our subject sequences. The same bag-of-words and convolutional approaches as well as the random and ESM base vectors are also applied here, but all starting from random vectors with values in $[-1, 1]$. These embeddings were assessed \textit{via} a scatter-plot of the two first principal components of their PCA projection. (insert firgures)

Since these algorithms are only available as PyTorch implementations, implementations in Julia have been made here. A stratified 10-fold cross validation of these models with our subject sequences has been performed. The learning rate is set at 0.035 and the amount of retraining iterations is set to 120. The results are provided in table~\ref{tab:phalpclassonline}. At first, there is generally a substantial increase in the performance of this model compared to the naive additive model. The single-pass model seems to have widely varying results depending on the type of embeddings used, with the bag-of-words embeddings generally performing better than the convolutional embeddings and also the ESM-based embeddings performing better than random base vectors. Iterative retraining of the model also seems to increase its performance significantly, even coming close to the performance of an XGBoost classifier in this case. Further improvement might be found when optimizing the models' parameters.

The cross validation procedure takes less than 10 seconds to run for the single-pass model, whilst doing a retraining of the model adds 2 to 3 minutes. This model appears to be a decently performing extension of the rudimentary hyperdimensional classification model for protein language modeling, whilst still being much more efficient than the commonly used machine learning models. The drawback of the model is that we cannot use hyperefficient bit-operations anymore, which limits its efficiency compared to the binary nature of the additive model.

\begin{table}[h]
    \caption{\label{tab:phalpclassonline}Results of type classifications using implementations of OnlineHD with several kinds of embeddings}
    \resizebox{\textwidth}{!}{\begin{tabular}{|c||c|c|c|c|}
        \hline
        \underline{F1-scores} & \textbf{BoW/random} & \textbf{BoW/ESM} & \textbf{Convolutional/random} & \textbf{Convolutional/ESM} \\
        \hline
        \textbf{Single-pass OnlineHD} & 0.8901 & 0.9214 & 0.7793 & 0.8400 \\
        \hline
        \textbf{Iterative OnlineHD} & 0.9487 & 0.9757 & 0.9486 & 0.9670 \\
        \hline
    \end{tabular}}
\end{table}

\section{Domain classification}
possible domain classification implementation, may or may not be interesting, but would be again a sequence classification (bit more complex perhaps) that we already tackled 