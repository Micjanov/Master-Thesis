@article{Kanerva2009,
abstract = {The 1990s saw the emergence of cognitive models that depend on very high dimensionality and randomness. They include Holographic Reduced Representations, Spatter Code, Semantic Vectors, Latent Semantic Analysis, Context-Dependent Thinning, and Vector-Symbolic Architecture. They represent things in highdimensional vectors that are manipulated by operations that produce new high-dimensional vectors in the style of traditional computing, in what is called here hyperdimensional computing on account of the very high dimensionality. The paper presents the main ideas behind these models, written as a tutorial essay in hopes of making the ideas accessible and even provocative. A sketch of how we have arrived at these models, with references and pointers to further reading, is given at the end. The thesis of the paper is that hyperdimensional representation has much to offer to students of cognitive science, theoretical neuroscience, computer science and engineering, and mathematics. {\textcopyright} 2009 Springer Science+Business Media, LLC.},
author = {Kanerva, Pentti},
doi = {10.1007/s12559-009-9009-8},
file = {:home/mfat/Unief/Thesis/references/kanerva09-hyperdimensional.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {Cognitive code,Holistic mapping,Holistic record,Holographic reduced representation,Random indexing,von Neumann architecture},
month = {jun},
number = {2},
pages = {139--159},
title = {{Hyperdimensional Computing: An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors}},
url = {http://link.springer.com/10.1007/s12559-009-9009-8},
volume = {1},
year = {2009}
}
@article{HRR,
  author={Plate, T.A.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Holographic reduced representations}, 
  year={1995},
  volume={6},
  number={3},
  pages={623-641},
  doi={10.1109/72.377968}
}
@article{spatter,
author="Kanerva, Pentti",
editor="Marinaro, Maria
and Morasso, Pietro G.",
title="The Spatter Code for Encoding Concepts at Many Levels",
booktitle="ICANN '94",
year="1994",
publisher="Springer London",
address="London",
pages="226--229",
abstract="The Spatter Code is a high-dimensional (e.g., N=10,000), random code that encodes ``high-level concepts'' in tenns of their ``low-level attributes'' so that concepts at different levels can be mixed freely. The binary spatter code is the simplest. It has two N-bit codewords for each concept or item, a ``high-level,'' or dense, word with many randomly placed Is and a ``low-level,'' or sparse, word with a few (that are contained in the many). The dense codewords can be used as inputs to an associative memory. The sparse codewords are used in encoding new concepts. When several items (attributes, concepts, chunks) are combined to form a new item, the two codewords for the new item are made from the sparse codewords of its constituents as follows: the new dense word is the logical OR of the constiblents (i.e., their sum thresholded at 0.5), and the new sparse word has Is where the constiblent words overlap (i.e., their sum thresholded at 1.5). When the parameters for the code are chosen properly, the number of Is in the codewords is maintained as new items are encoded from combinations of old ones.",
isbn="978-1-4471-2097-1"
}
@article{binBund,
author = {Schmuck, Manuel and Benini, Luca and Rahimi, Abbas},
title = {Hardware Optimizations of Dense Binary Hyperdimensional Computing: Rematerialization of Hypervectors, Binarized Bundling, and Combinational Associative Memory},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/3314326},
doi = {10.1145/3314326},
abstract = {Brain-inspired hyperdimensional (HD) computing models neural activity patterns of the very size of the brain’s circuits with points of a hyperdimensional space, that is, with hypervectors. Hypervectors are D-dimensional (pseudo)random vectors with independent and identically distributed (i.i.d.) components constituting ultra-wide holographic words: D=10,000 bits, for instance. At its very core, HD computing manipulates a set of seed hypervectors to build composite hypervectors representing objects of interest. It demands memory optimizations with simple operations for an efficient hardware realization. In this article, we propose hardware techniques for optimizations of HD computing, in a synthesizable open-source VHDL library, to enable co-located implementation of both learning and classification tasks on only a small portion of Xilinx UltraScale FPGAs: (1) We propose simple logical operations to rematerialize the hypervectors on the fly rather than loading them from memory. These operations massively reduce the memory footprint by directly computing the composite hypervectors whose individual seed hypervectors do not need to be stored in memory. (2) Bundling a series of hypervectors over time requires a multibit counter per every hypervector component. We instead propose a binarized back-to-back bundling without requiring any counters. This truly enables on-chip learning with minimal resources as every hypervector component remains binary over the course of training to avoid otherwise multibit components. (3) For every classification event, an associative memory is in charge of finding the closest match between a set of learned hypervectors and a query hypervector by using a distance metric. This operator is proportional to hypervector dimension (D), and hence may take O(D) cycles per classification event. Accordingly, we significantly improve the throughput of classification by proposing associative memories that steadily reduce the latency of classification to the extreme of a single cycle. (4) We perform a design space exploration incorporating the proposed techniques on FPGAs for a wearable biosignal processing application as a case study. Our techniques achieve up to 2.39\texttimes{} area saving, or 2,337\texttimes{} throughput improvement. The Pareto optimal HD architecture is mapped on only 18,340 configurable logic blocks (CLBs) to learn and classify five hand gestures using four electromyography sensors.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {oct},
articleno = {32},
numpages = {25},
keywords = {Hyperdimensional computing, single-cycle associative memory, binarized temporal bundling, electromyography, biosignals, on-chip learning, FPGA, rematerialization}
}
@article{HD_rev,
	doi = {10.1109/mcas.2020.2988388},
  
	url = {https://doi.org/10.1109%2Fmcas.2020.2988388},
  
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {20},
  
	number = {2},
  
	pages = {30--47},
  
	author = {Lulu Ge and Keshab K. Parhi},
  
	title = {Classification Using Hyperdimensional Computing: A Review},
  
	journal = {{IEEE} Circuits and Systems Magazine}
}
@article{primstruct,
author = {FRUTON, JOSEPH S.},
title = {Early Theories of Protein Structure},
journal = {Annals of the New York Academy of Sciences},
volume = {325},
number = {1},
pages = {1-20},
doi = {https://doi.org/10.1111/j.1749-6632.1979.tb14125.x},
url = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-6632.1979.tb14125.x},
eprint = {https://nyaspubs.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1749-6632.1979.tb14125.x},
year = {1979}
}
@Article{protseq,
AUTHOR = {König, Simone and Obermann, Wolfgang M. J. and Eble, Johannes A.},
TITLE = {The Current State-of-the-Art Identification of Unknown Proteins Using Mass Spectrometry Exemplified on De Novo Sequencing of a Venom Protease from Bothrops moojeni},
JOURNAL = {Molecules},
VOLUME = {27},
YEAR = {2022},
NUMBER = {15},
ARTICLE-NUMBER = {4976},
URL = {https://www.mdpi.com/1420-3049/27/15/4976},
PubMedID = {35956926},
ISSN = {1420-3049},
ABSTRACT = {(1) Background: The amino acid sequence elucidation of peptides from the gas phase fragmentation mass spectra, de novo sequencing, is a valuable method for the identification of unknown proteins complementary to Edman sequencing. It is increasingly used in shot-gun mass spectrometry (MS)-based proteomics experiments. We review the current state-of-the-art and use the identification of an unknown snake venom protein targeting the human tissue factor (TF) as an example to describe the analysis process based on manual spectrum interrogation. (2) Methods: The immobilized TF was incubated with a crude B. moojeni venom solution. The potential binding partners were eluted and further purified by gel electrophoresis. Edman degradation was performed to elucidate the N-terminus of the 31 kDa protein of interest. High-resolution MS with collision-induced dissociation was employed to generate peptide fragmentation spectra. Sequence tags were deduced and used for searches in the NCBI and Uniprot databases. Protein matches from the snake species were further validated by target MS/MS. (3) Results: Sequence tag D [K/Q] D [I/L] VDD [K/Q] led to a snake venom serine protease (SVSP) from lancehead B. jararaca (P81824). With target MS/MS, 24% of the SVSP sequence were confirmed; an additional 41% were tentatively assigned by data-independent MS. Edman sequencing provided information for 10 N-terminal amino acid residues, also confirming the match to SVSP. (4) Conclusions: The identification of unknown proteins continues to be a challenge despite major advances in MS instrumentation and bioinformatic tools. The main requirement is the generation of meaningful, high-quality MS peptide fragmentation spectra. These are used to elucidate sufficiently long sequence tags, which can subsequently be submitted to searches in protein databases. This basic method does not require extensive bioinformatics because peptide MS/MS spectra, especially of doubly-charged ions, can be analysed manually. We demonstrated the procedure with the elucidation of SVSP. While de novo sequencing quickly indicates the correct protein group, the validation of the entire protein sequence of amino acid-by-amino acid will take time. Reasons are the need to properly assign isobaric amino acid residues and modifications. With the ongoing efforts in genomics and transcriptomics and the availability of ever more data in public databases, the need for de novo MS sequencing will decrease. Still, not every animal and plant species will be sequenced, so the combination of MS and Edman sequencing will continue to be of importance for the identification of unknown proteins.},
DOI = {10.3390/molecules27154976}
}
@article{structure,
author = {Ptitsyn, O.B.},
title = {How does protein synthesis give rise to the 3D-structure?},
journal = {FEBS Letters},
volume = {285},
number = {2},
pages = {176-181},
keywords = {Protein folding, Molten globule, Kinetic intermediate, NMR of protein, Tertiary fold},
doi = {https://doi.org/10.1016/0014-5793(91)80799-9},
url = {https://febs.onlinelibrary.wiley.com/doi/abs/10.1016/0014-5793%2891%2980799-9},
eprint = {https://febs.onlinelibrary.wiley.com/doi/pdf/10.1016/0014-5793%2891%2980799-9},
abstract = {The recent experimental data on stages and kinetic intermediates in protein folding are reviewed. It is emphasized that these data are consistent with the ‘framework model’ proposed by the author in 1973. The model implies that protein folds by stage mechanism (secondary structure — molten globule state — native state) in such a way that the results of previous stages are not reconsidered in subsequent ones. Arguments are presented that both these hypotheses and available experimental data do not contradict the assumption that native structures of at least small proteins are nevertheless under thermodynamic rather than kinetic control, i.e. correspond to global minima of free energy.},
year = {1991}
}