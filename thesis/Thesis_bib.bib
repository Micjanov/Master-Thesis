@article{Kanerva2009,
abstract = {The 1990s saw the emergence of cognitive models that depend on very high dimensionality and randomness. They include Holographic Reduced Representations, Spatter Code, Semantic Vectors, Latent Semantic Analysis, Context-Dependent Thinning, and Vector-Symbolic Architecture. They represent things in highdimensional vectors that are manipulated by operations that produce new high-dimensional vectors in the style of traditional computing, in what is called here hyperdimensional computing on account of the very high dimensionality. The paper presents the main ideas behind these models, written as a tutorial essay in hopes of making the ideas accessible and even provocative. A sketch of how we have arrived at these models, with references and pointers to further reading, is given at the end. The thesis of the paper is that hyperdimensional representation has much to offer to students of cognitive science, theoretical neuroscience, computer science and engineering, and mathematics. {\textcopyright} 2009 Springer Science+Business Media, LLC.},
author = {Kanerva, Pentti},
doi = {10.1007/s12559-009-9009-8},
file = {:home/mfat/Unief/Thesis/references/kanerva09-hyperdimensional.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {Cognitive code,Holistic mapping,Holistic record,Holographic reduced representation,Random indexing,von Neumann architecture},
month = {jun},
number = {2},
pages = {139--159},
title = {{Hyperdimensional Computing: An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors}},
url = {http://link.springer.com/10.1007/s12559-009-9009-8},
volume = {1},
year = {2009}
}

@article{HRR,
  author={Plate, T.A.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Holographic reduced representations}, 
  year={1995},
  volume={6},
  number={3},
  pages={623-641},
  doi={10.1109/72.377968}}

@article{spatter,
author="Kanerva, Pentti",
editor="Marinaro, Maria
and Morasso, Pietro G.",
title="The Spatter Code for Encoding Concepts at Many Levels",
booktitle="ICANN '94",
year="1994",
publisher="Springer London",
address="London",
pages="226--229",
abstract="The Spatter Code is a high-dimensional (e.g., N=10,000), random code that encodes ``high-level concepts'' in tenns of their ``low-level attributes'' so that concepts at different levels can be mixed freely. The binary spatter code is the simplest. It has two N-bit codewords for each concept or item, a ``high-level,'' or dense, word with many randomly placed Is and a ``low-level,'' or sparse, word with a few (that are contained in the many). The dense codewords can be used as inputs to an associative memory. The sparse codewords are used in encoding new concepts. When several items (attributes, concepts, chunks) are combined to form a new item, the two codewords for the new item are made from the sparse codewords of its constituents as follows: the new dense word is the logical OR of the constiblents (i.e., their sum thresholded at 0.5), and the new sparse word has Is where the constiblent words overlap (i.e., their sum thresholded at 1.5). When the parameters for the code are chosen properly, the number of Is in the codewords is maintained as new items are encoded from combinations of old ones.",
isbn="978-1-4471-2097-1"
}