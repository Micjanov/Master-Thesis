@article{Kanerva2009,
abstract = {The 1990s saw the emergence of cognitive models that depend on very high dimensionality and randomness. They include Holographic Reduced Representations, Spatter Code, Semantic Vectors, Latent Semantic Analysis, Context-Dependent Thinning, and Vector-Symbolic Architecture. They represent things in highdimensional vectors that are manipulated by operations that produce new high-dimensional vectors in the style of traditional computing, in what is called here hyperdimensional computing on account of the very high dimensionality. The paper presents the main ideas behind these models, written as a tutorial essay in hopes of making the ideas accessible and even provocative. A sketch of how we have arrived at these models, with references and pointers to further reading, is given at the end. The thesis of the paper is that hyperdimensional representation has much to offer to students of cognitive science, theoretical neuroscience, computer science and engineering, and mathematics. {\textcopyright} 2009 Springer Science+Business Media, LLC.},
author = {Kanerva, Pentti},
doi = {10.1007/s12559-009-9009-8},
file = {:home/mfat/Unief/Thesis/references/kanerva09-hyperdimensional.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {Cognitive code,Holistic mapping,Holistic record,Holographic reduced representation,Random indexing,von Neumann architecture},
month = {jun},
number = {2},
pages = {139--159},
title = {{Hyperdimensional Computing: An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors}},
url = {http://link.springer.com/10.1007/s12559-009-9009-8},
volume = {1},
year = {2009}
}
@article{HRR,
  author={Plate, T.A.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Holographic reduced representations}, 
  year={1995},
  volume={6},
  number={3},
  pages={623-641},
  doi={10.1109/72.377968}
}
@article{spatter,
author="Kanerva, Pentti",
editor="Marinaro, Maria
and Morasso, Pietro G.",
title="The Spatter Code for Encoding Concepts at Many Levels",
booktitle="ICANN '94",
year="1994",
publisher="Springer London",
address="London",
pages="226--229",
abstract="The Spatter Code is a high-dimensional (e.g., N=10,000), random code that encodes ``high-level concepts'' in tenns of their ``low-level attributes'' so that concepts at different levels can be mixed freely. The binary spatter code is the simplest. It has two N-bit codewords for each concept or item, a ``high-level,'' or dense, word with many randomly placed Is and a ``low-level,'' or sparse, word with a few (that are contained in the many). The dense codewords can be used as inputs to an associative memory. The sparse codewords are used in encoding new concepts. When several items (attributes, concepts, chunks) are combined to form a new item, the two codewords for the new item are made from the sparse codewords of its constituents as follows: the new dense word is the logical OR of the constiblents (i.e., their sum thresholded at 0.5), and the new sparse word has Is where the constiblent words overlap (i.e., their sum thresholded at 1.5). When the parameters for the code are chosen properly, the number of Is in the codewords is maintained as new items are encoded from combinations of old ones.",
isbn="978-1-4471-2097-1"
}
@article{binBund,
author = {Schmuck, Manuel and Benini, Luca and Rahimi, Abbas},
title = {Hardware Optimizations of Dense Binary Hyperdimensional Computing: Rematerialization of Hypervectors, Binarized Bundling, and Combinational Associative Memory},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/3314326},
doi = {10.1145/3314326},
abstract = {Brain-inspired hyperdimensional (HD) computing models neural activity patterns of the very size of the brain’s circuits with points of a hyperdimensional space, that is, with hypervectors. Hypervectors are D-dimensional (pseudo)random vectors with independent and identically distributed (i.i.d.) components constituting ultra-wide holographic words: D=10,000 bits, for instance. At its very core, HD computing manipulates a set of seed hypervectors to build composite hypervectors representing objects of interest. It demands memory optimizations with simple operations for an efficient hardware realization. In this article, we propose hardware techniques for optimizations of HD computing, in a synthesizable open-source VHDL library, to enable co-located implementation of both learning and classification tasks on only a small portion of Xilinx UltraScale FPGAs: (1) We propose simple logical operations to rematerialize the hypervectors on the fly rather than loading them from memory. These operations massively reduce the memory footprint by directly computing the composite hypervectors whose individual seed hypervectors do not need to be stored in memory. (2) Bundling a series of hypervectors over time requires a multibit counter per every hypervector component. We instead propose a binarized back-to-back bundling without requiring any counters. This truly enables on-chip learning with minimal resources as every hypervector component remains binary over the course of training to avoid otherwise multibit components. (3) For every classification event, an associative memory is in charge of finding the closest match between a set of learned hypervectors and a query hypervector by using a distance metric. This operator is proportional to hypervector dimension (D), and hence may take O(D) cycles per classification event. Accordingly, we significantly improve the throughput of classification by proposing associative memories that steadily reduce the latency of classification to the extreme of a single cycle. (4) We perform a design space exploration incorporating the proposed techniques on FPGAs for a wearable biosignal processing application as a case study. Our techniques achieve up to 2.39\texttimes{} area saving, or 2,337\texttimes{} throughput improvement. The Pareto optimal HD architecture is mapped on only 18,340 configurable logic blocks (CLBs) to learn and classify five hand gestures using four electromyography sensors.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {oct},
articleno = {32},
numpages = {25},
keywords = {Hyperdimensional computing, single-cycle associative memory, binarized temporal bundling, electromyography, biosignals, on-chip learning, FPGA, rematerialization}
}
@article{HD_rev,
	doi = {10.1109/mcas.2020.2988388},
  
	url = {https://doi.org/10.1109%2Fmcas.2020.2988388},
  
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {20},
  
	number = {2},
  
	pages = {30--47},
  
	author = {Lulu Ge and Keshab K. Parhi},
  
	title = {Classification Using Hyperdimensional Computing: A Review},
  
	journal = {{IEEE} Circuits and Systems Magazine}
}
@article{primstruct,
author = {FRUTON, JOSEPH S.},
title = {Early Theories of Protein Structure},
journal = {Annals of the New York Academy of Sciences},
volume = {325},
number = {1},
pages = {1-20},
doi = {https://doi.org/10.1111/j.1749-6632.1979.tb14125.x},
url = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-6632.1979.tb14125.x},
eprint = {https://nyaspubs.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1749-6632.1979.tb14125.x},
year = {1979}
}
@Article{protseq,
AUTHOR = {König, Simone and Obermann, Wolfgang M. J. and Eble, Johannes A.},
TITLE = {The Current State-of-the-Art Identification of Unknown Proteins Using Mass Spectrometry Exemplified on De Novo Sequencing of a Venom Protease from Bothrops moojeni},
JOURNAL = {Molecules},
VOLUME = {27},
YEAR = {2022},
NUMBER = {15},
ARTICLE-NUMBER = {4976},
URL = {https://www.mdpi.com/1420-3049/27/15/4976},
PubMedID = {35956926},
ISSN = {1420-3049},
ABSTRACT = {(1) Background: The amino acid sequence elucidation of peptides from the gas phase fragmentation mass spectra, de novo sequencing, is a valuable method for the identification of unknown proteins complementary to Edman sequencing. It is increasingly used in shot-gun mass spectrometry (MS)-based proteomics experiments. We review the current state-of-the-art and use the identification of an unknown snake venom protein targeting the human tissue factor (TF) as an example to describe the analysis process based on manual spectrum interrogation. (2) Methods: The immobilized TF was incubated with a crude B. moojeni venom solution. The potential binding partners were eluted and further purified by gel electrophoresis. Edman degradation was performed to elucidate the N-terminus of the 31 kDa protein of interest. High-resolution MS with collision-induced dissociation was employed to generate peptide fragmentation spectra. Sequence tags were deduced and used for searches in the NCBI and Uniprot databases. Protein matches from the snake species were further validated by target MS/MS. (3) Results: Sequence tag D [K/Q] D [I/L] VDD [K/Q] led to a snake venom serine protease (SVSP) from lancehead B. jararaca (P81824). With target MS/MS, 24% of the SVSP sequence were confirmed; an additional 41% were tentatively assigned by data-independent MS. Edman sequencing provided information for 10 N-terminal amino acid residues, also confirming the match to SVSP. (4) Conclusions: The identification of unknown proteins continues to be a challenge despite major advances in MS instrumentation and bioinformatic tools. The main requirement is the generation of meaningful, high-quality MS peptide fragmentation spectra. These are used to elucidate sufficiently long sequence tags, which can subsequently be submitted to searches in protein databases. This basic method does not require extensive bioinformatics because peptide MS/MS spectra, especially of doubly-charged ions, can be analysed manually. We demonstrated the procedure with the elucidation of SVSP. While de novo sequencing quickly indicates the correct protein group, the validation of the entire protein sequence of amino acid-by-amino acid will take time. Reasons are the need to properly assign isobaric amino acid residues and modifications. With the ongoing efforts in genomics and transcriptomics and the availability of ever more data in public databases, the need for de novo MS sequencing will decrease. Still, not every animal and plant species will be sequenced, so the combination of MS and Edman sequencing will continue to be of importance for the identification of unknown proteins.},
DOI = {10.3390/molecules27154976}
}
@article{structure,
author = {Ptitsyn, O.B.},
title = {How does protein synthesis give rise to the 3D-structure?},
journal = {FEBS Letters},
volume = {285},
number = {2},
pages = {176-181},
keywords = {Protein folding, Molten globule, Kinetic intermediate, NMR of protein, Tertiary fold},
doi = {https://doi.org/10.1016/0014-5793(91)80799-9},
url = {https://febs.onlinelibrary.wiley.com/doi/abs/10.1016/0014-5793%2891%2980799-9},
eprint = {https://febs.onlinelibrary.wiley.com/doi/pdf/10.1016/0014-5793%2891%2980799-9},
abstract = {The recent experimental data on stages and kinetic intermediates in protein folding are reviewed. It is emphasized that these data are consistent with the ‘framework model’ proposed by the author in 1973. The model implies that protein folds by stage mechanism (secondary structure — molten globule state — native state) in such a way that the results of previous stages are not reconsidered in subsequent ones. Arguments are presented that both these hypotheses and available experimental data do not contradict the assumption that native structures of at least small proteins are nevertheless under thermodynamic rather than kinetic control, i.e. correspond to global minima of free energy.},
year = {1991}
}
@article{global,
title = {A general method applicable to the search for similarities in the amino acid sequence of two proteins},
journal = {Journal of Molecular Biology},
volume = {48},
number = {3},
pages = {443-453},
year = {1970},
issn = {0022-2836},
doi = {https://doi.org/10.1016/0022-2836(70)90057-4},
url = {https://www.sciencedirect.com/science/article/pii/0022283670900574},
author = {Saul B. Needleman and Christian D. Wunsch},
abstract = {A computer adaptable method for finding similarities in the amino acid sequences of two proteins has been developed. From these findings it is possible to determine whether significant homology exists between the proteins. This information is used to trace their possible evolutionary development. The maximum match is a number dependent upon the similarity of the sequences. One of its definitions is the largest number of amino acids of one protein that can be matched with those of a second protein allowing for all possible interruptions in either of the sequences. While the interruptions give rise to a very large number of comparisons, the method efficiently excludes from consideration those comparisons that cannot contribute to the maximum match. Comparisons are made from the smallest unit of significance, a pair of amino acids, one from each protein. All possible pairs are represented by a two-dimensional array, and all possible comparisons are represented by pathways through the array. For this maximum match only certain of the possible pathways must be evaluated. A numerical value, one in this case, is assigned to every cell in the array representing like amino acids. The maximum match is the largest number that would result from summing the cell values of every pathway.}
}
@article{local,
title = {Identification of common molecular subsequences},
journal = {Journal of Molecular Biology},
volume = {147},
number = {1},
pages = {195-197},
year = {1981},
issn = {0022-2836},
doi = {https://doi.org/10.1016/0022-2836(81)90087-5},
url = {https://www.sciencedirect.com/science/article/pii/0022283681900875},
author = {T.F. Smith and M.S. Waterman}
}
@article{fasta,
author = {David J. Lipman  and William R. Pearson },
title = {Rapid and Sensitive Protein Similarity Searches},
journal = {Science},
volume = {227},
number = {4693},
pages = {1435-1441},
year = {1985},
doi = {10.1126/science.2983426},
URL = {https://www.science.org/doi/abs/10.1126/science.2983426},
eprint = {https://www.science.org/doi/pdf/10.1126/science.2983426},
abstract = {An algorithm was developed which facilitates the search for similarities between newly determined amino acid sequences and sequences already available in databases. Because of the algorithm's efficiency on many microcomputers, sensitive protein database searches may now become a routine procedure for molecular biologists. The method efficiently identifies regions of similar sequence and then scores the aligned identical and differing residues in those regions by means of an amino acid replaceability matrix. This matrix increases sensitivity by giving high scores to those amino acid replacements which occur frequently in evolution. The algorithm has been implemented in a computer program designed to search protein databases very rapidly. For example, comparison of a 200-amino-acid sequence to the 500,000 residues in the National Biomedical Research Foundation library would take less than 2 minutes on a minicomputer, and less than 10 minutes on a microcomputer (IBM PC).}
}
@article{blast,
title = {Basic local alignment search tool},
journal = {Journal of Molecular Biology},
volume = {215},
number = {3},
pages = {403-410},
year = {1990},
issn = {0022-2836},
doi = {https://doi.org/10.1016/S0022-2836(05)80360-2},
url = {https://www.sciencedirect.com/science/article/pii/S0022283605803602},
author = {Stephen F. Altschul and Warren Gish and Webb Miller and Eugene W. Myers and David J. Lipman},
abstract = {A new approach to rapid sequence comparison, basic local alignment search tool (BLAST), directly approximates alignments that optimize a measure of local similarity, the maximal segment pair (MSP) score. Recent mathematical results on the stochastic properties of MSP scores allow an analysis of the performance of this method as well as the statistical significance of alignments it generates. The basic algorithm is simple and robust; it can be implemented in a number of ways and applied in a variety of contexts including straight-forward DNA and protein sequence database searches, motif searches, gene identification searches, and in the analysis of multiple regions of similarity in long DNA sequences. In addition to its flexibility and tractability to mathematical analysis, BLAST is an order of magnitude faster than existing sequence comparison tools of comparable sensitivity.}
}
@article{xray,
  doi = {10.1038/181662a0},
  url = {https://doi.org/10.1038/181662a0},
  year = {1958},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {181},
  number = {4610},
  pages = {662--666},
  author = {J. C. Kendrew and G. Bodo and H. M. Dintzis and R. G. Parrish and H. Wyckoff and D. C. Phillips},
  title = {A Three-Dimensional Model of the Myoglobin Molecule Obtained by X-Ray Analysis},
  journal = {Nature}
}
@article{cyroem,
  doi = {10.1038/s41586-020-2833-4},
  url = {https://doi.org/10.1038/s41586-020-2833-4},
  year = {2020},
  month = oct,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {587},
  number = {7832},
  pages = {157--161},
  author = {Ka Man Yip and Niels Fischer and Elham Paknia and Ashwin Chari and Holger Stark},
  title = {Atomic-resolution protein structure determination by cryo-{EM}},
  journal = {Nature}
}
@article{psiblast,
  doi = {10.1093/nar/25.17.3389},
  url = {https://doi.org/10.1093/nar/25.17.3389},
  year = {1997},
  month = sep,
  publisher = {Oxford University Press ({OUP})},
  volume = {25},
  number = {17},
  pages = {3389--3402},
  author = {S. Altschul},
  title = {Gapped {BLAST} and {PSI}-{BLAST}: a new generation of protein database search programs},
  journal = {Nucleic Acids Research}
}
@article{hhblits3,
  doi = {10.1186/s12859-019-3019-7},
  url = {https://doi.org/10.1186/s12859-019-3019-7},
  year = {2019},
  month = sep,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {20},
  number = {1},
  author = {Martin Steinegger and Markus Meier and Milot Mirdita and Harald V\"{o}hringer and Stephan J. Haunsberger and Johannes S\"{o}ding},
  title = {{HH}-suite3 for fast remote homology detection and deep protein annotation},
  journal = {{BMC} Bioinformatics}
}
@article{mmseqs2,
  doi = {10.1038/nbt.3988},
  url = {https://doi.org/10.1038/nbt.3988},
  year = {2017},
  month = oct,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {35},
  number = {11},
  pages = {1026--1028},
  author = {Martin Steinegger and Johannes S\"{o}ding},
  title = {{MMseqs}2 enables sensitive protein sequence searching for the analysis of massive data sets},
  journal = {Nature Biotechnology}
}
@incollection{rosetta,
  doi = {10.1016/b978-0-12-381270-4.00019-6},
  url = {https://doi.org/10.1016/b978-0-12-381270-4.00019-6},
  year = {2011},
  publisher = {Elsevier},
  pages = {545--574},
  author = {Andrew Leaver-Fay and Michael Tyka and Steven M. Lewis and Oliver F. Lange and James Thompson and Ron Jacak and Kristian W. Kaufman and P. Douglas Renfrew and Colin A. Smith and Will Sheffler and Ian W. Davis and Seth Cooper and Adrien Treuille and Daniel J. Mandell and Florian Richter and Yih-En Andrew Ban and Sarel J. Fleishman and Jacob E. Corn and David E. Kim and Sergey Lyskov and Monica Berrondo and Stuart Mentzer and Zoran Popovi{\'{c}} and James J. Havranek and John Karanicolas and Rhiju Das and Jens Meiler and Tanja Kortemme and Jeffrey J. Gray and Brian Kuhlman and David Baker and Philip Bradley},
  title = {Rosetta3},
  booktitle = {Computer Methods,  Part C}
}
@article{review,
  doi = {10.1016/j.cels.2021.05.017},
  url = {https://doi.org/10.1016/j.cels.2021.05.017},
  year = {2021},
  month = jun,
  publisher = {Elsevier {BV}},
  volume = {12},
  number = {6},
  pages = {654--669.e3},
  author = {Tristan Bepler and Bonnie Berger},
  title = {Learning the protein language: Evolution,  structure,  and function},
  journal = {Cell Systems}
}
@article{dnastruct,
  doi = {10.1038/171737a0},
  url = {https://doi.org/10.1038/171737a0},
  year = {1953},
  month = apr,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {171},
  number = {4356},
  pages = {737--738},
  author = {J. D. WATSON and F. H. C. CRICK},
  title = {Molecular Structure of Nucleic Acids: A Structure for Deoxyribose Nucleic Acid},
  journal = {Nature}
}
@article{dogma,
  doi = {10.1038/227561a0},
  url = {https://doi.org/10.1038/227561a0},
  year = {1970},
  month = aug,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {227},
  number = {5258},
  pages = {561--563},
  author = {FRANCIS CRICK},
  title = {Central Dogma of Molecular Biology},
  journal = {Nature}
}
@article{insulin,
  doi = {10.1042/bj0530353},
  url = {https://doi.org/10.1042/bj0530353},
  year = {1953},
  month = feb,
  publisher = {Portland Press Ltd.},
  volume = {53},
  number = {3},
  pages = {353--366},
  author = {F. Sanger and E. O. P. Thompson},
  title = {The amino-acid sequence in the glycyl chain of insulin. 1. The identification of lower peptides from partial hydrolysates},
  journal = {Biochemical Journal}
}
@book{comprotein,
  title={Proceedings of the December 4-6, 1962, Fall Joint Computer Conference},
  author={Leas, J Wesley},
  year={1962},
  publisher={ACM}
}
@article{atlas,
  doi = {10.2307/2412074},
  url = {https://doi.org/10.2307/2412074},
  year = {1967},
  month = sep,
  publisher = {Oxford University Press ({OUP})},
  volume = {16},
  number = {3},
  pages = {262},
  author = {Robert T. Hersh and Richard V. Eck and Margaret O. Dayhoff},
  title = {Atlas of Protein Sequence and Structure,  1966.},
  journal = {Systematic Zoology}
}
@article{codon,
  title={The origin of the genetic code},
  author={Crick, Francis HC},
  journal={Journal of molecular biology},
  volume={38},
  number={3},
  pages={367--379},
  year={1968},
  publisher={Elsevier}
}
@article{msa,
  title={Simultaneous comparison of three protein sequences.},
  author={Murata, Michio and Richardson, Jane S and Sussman, Joel L},
  journal={Proceedings of the National Academy of Sciences},
  volume={82},
  number={10},
  pages={3073--3077},
  year={1985},
  publisher={National Acad Sciences}
}
@article{clustal,
  title={CLUSTAL: a package for performing multiple sequence alignment on a microcomputer},
  author={Higgins, Desmond G and Sharp, Paul M},
  journal={Gene},
  volume={73},
  number={1},
  pages={237--244},
  year={1988},
  publisher={Elsevier}
}
@article{muscle,
  title={MUSCLE: multiple sequence alignment with high accuracy and high throughput},
  author={Edgar, Robert C},
  journal={Nucleic acids research},
  volume={32},
  number={5},
  pages={1792--1797},
  year={2004},
  publisher={Oxford University Press}
}
@article{rna,
  doi = {10.1038/237082a0},
  url = {https://doi.org/10.1038/237082a0},
  year = {1972},
  month = may,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {237},
  number = {5350},
  pages = {82--88},
  author = {W. MIN JOU and G. HAEGEMAN and M. YSEBAERT and W. FIERS},
  title = {Nucleotide Sequence of the Gene Coding for the Bacteriophage {MS}2 Coat Protein},
  journal = {Nature}
}
@ARTICLE{dnaseq,
  title    = "Nucleotide sequence of bacteriophage phi {X174} {DNA}",
  author   = "Sanger, F and Air, G M and Barrell, B G and Brown, N L and
              Coulson, A R and Fiddes, C A and Hutchison, C A and Slocombe, P M
              and Smith, M",
  abstract = "A DNA sequence for the genome of bacteriophage phi X174 of
              approximately 5,375 nucleotides has been determined using the
              rapid and simple 'plus and minus' method. The sequence identifies
              many of the features responsible for the production of the
              proteins of the nine known genes of the organism, including
              initiation and termination sites for the proteins and RNAs. Two
              pairs of genes are coded by the same region of DNA using
              different reading frames.",
  journal  = "Nature",
  volume   =  265,
  number   =  5596,
  pages    = "687--695",
  month    =  feb,
  year     =  1977,
  language = "en"
}
@article{alphafold2,
  doi = {10.1038/s41586-021-03819-2},
  url = {https://doi.org/10.1038/s41586-021-03819-2},
  year = {2021},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {596},
  number = {7873},
  pages = {583--589},
  author = {John Jumper and Richard Evans and Alexander Pritzel and Tim Green and Michael Figurnov and Olaf Ronneberger and Kathryn Tunyasuvunakool and Russ Bates and Augustin {\v{Z}}{\'{\i}}dek and Anna Potapenko and Alex Bridgland and Clemens Meyer and Simon A. A. Kohl and Andrew J. Ballard and Andrew Cowie and Bernardino Romera-Paredes and Stanislav Nikolov and Rishub Jain and Jonas Adler and Trevor Back and Stig Petersen and David Reiman and Ellen Clancy and Michal Zielinski and Martin Steinegger and Michalina Pacholska and Tamas Berghammer and Sebastian Bodenstein and David Silver and Oriol Vinyals and Andrew W. Senior and Koray Kavukcuoglu and Pushmeet Kohli and Demis Hassabis},
  title = {Highly accurate protein structure prediction with {AlphaFold}},
  journal = {Nature}
}
@article{alphafold,
  doi = {10.1093/bioinformatics/btz422},
  url = {https://doi.org/10.1093/bioinformatics/btz422},
  year = {2019},
  month = may,
  publisher = {Oxford University Press ({OUP})},
  volume = {35},
  number = {22},
  pages = {4862--4865},
  author = {Mohammed AlQuraishi},
  editor = {Alfonso Valencia},
  title = {{AlphaFold} at {CASP}13},
  journal = {Bioinformatics}
}
@misc{elmo,
  doi = {10.48550/ARXIV.1802.05365},
  url = {https://arxiv.org/abs/1802.05365},
  author = {Peters,  Matthew E. and Neumann,  Mark and Iyyer,  Mohit and Gardner,  Matt and Clark,  Christopher and Lee,  Kenton and Zettlemoyer,  Luke},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Deep contextualized word representations},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{bert,
  doi = {10.48550/ARXIV.1810.04805},
  url = {https://arxiv.org/abs/1810.04805},
  author = {Devlin,  Jacob and Chang,  Ming-Wei and Lee,  Kenton and Toutanova,  Kristina},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{gpt3,
  doi = {10.48550/ARXIV.2005.14165},
  url = {https://arxiv.org/abs/2005.14165},
  author = {Brown,  Tom B. and Mann,  Benjamin and Ryder,  Nick and Subbiah,  Melanie and Kaplan,  Jared and Dhariwal,  Prafulla and Neelakantan,  Arvind and Shyam,  Pranav and Sastry,  Girish and Askell,  Amanda and Agarwal,  Sandhini and Herbert-Voss,  Ariel and Krueger,  Gretchen and Henighan,  Tom and Child,  Rewon and Ramesh,  Aditya and Ziegler,  Daniel M. and Wu,  Jeffrey and Winter,  Clemens and Hesse,  Christopher and Chen,  Mark and Sigler,  Eric and Litwin,  Mateusz and Gray,  Scott and Chess,  Benjamin and Clark,  Jack and Berner,  Christopher and McCandlish,  Sam and Radford,  Alec and Sutskever,  Ilya and Amodei,  Dario},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Language Models are Few-Shot Learners},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{prottrans,
  doi = {10.48550/ARXIV.2007.06225},
  url = {https://arxiv.org/abs/2007.06225},
  author = {Elnaggar,  Ahmed and Heinzinger,  Michael and Dallago,  Christian and Rihawi,  Ghalia and Wang,  Yu and Jones,  Llion and Gibbs,  Tom and Feher,  Tamas and Angerer,  Christoph and Steinegger,  Martin and Bhowmik,  Debsindhu and Rost,  Burkhard},
  keywords = {Machine Learning (cs.LG),  Computation and Language (cs.CL),  Distributed,  Parallel,  and Cluster Computing (cs.DC),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {ProtTrans: Towards Cracking the Language of Life's Code Through Self-Supervised Deep Learning and High Performance Computing},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@misc{tape,
  doi = {10.48550/ARXIV.1906.08230},
  url = {https://arxiv.org/abs/1906.08230},
  author = {Rao,  Roshan and Bhattacharya,  Nicholas and Thomas,  Neil and Duan,  Yan and Chen,  Xi and Canny,  John and Abbeel,  Pieter and Song,  Yun S.},
  keywords = {Machine Learning (cs.LG),  Biomolecules (q-bio.BM),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Biological sciences,  FOS: Biological sciences},
  title = {Evaluating Protein Transfer Learning with TAPE},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@article{esm2,
  doi = {10.1101/2022.07.20.500902},
  url = {https://doi.org/10.1101/2022.07.20.500902},
  year = {2022},
  month = jul,
  publisher = {Cold Spring Harbor Laboratory},
  author = {Zeming Lin and Halil Akin and Roshan Rao and Brian Hie and Zhongkai Zhu and Wenting Lu and Nikita Smetanin and Robert Verkuil and Ori Kabeli and Yaniv Shmueli and Allan dos Santos Costa and Maryam Fazel-Zarandi and Tom Sercu and Salvatore Candido and Alexander Rives},
  title = {Evolutionary-scale prediction of atomic level protein structure with a language model}
}
@misc{zoo, 
 title={Zoo Animal Classification}, 
 url={https://www.kaggle.com/datasets/uciml/zoo-animal-classification}, 
 journal={Kaggle}, 
 author={UCI Machine Learning}, 
 year={2016}
} 