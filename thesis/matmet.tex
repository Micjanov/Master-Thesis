\chapter[Materials and methods]{Materials and methods}
\section{Amino acid embeddings}
insert picture transformer ish model
\section{Case study: PhaLP dataset}
As of March 2023, the latest version of the PhaLP database, ~\textit{v2021\_04}, has been used to test our models.

\subsection*{Sequence embeddings}
In chapter~\ref{ssec:protclas}, a method of embedding sequences of amino acids has already been discussed. Here, a sequence of amino acids is considered to be a bag of k-mers. Within a k-mer, the amino acids (presented as randomly generated hyperdimensional vectors) are bonded together with sequential information included. All possible k-mers are all then bundled together, the result is then a hyperdimensional vector representing the whole sequence. We also introduce a novel sequence embedding method within the framework of hyperdimensional computing. It is similar to the bag-of-words method in the sense that it bundles vectors of k-mers, but here, the k-mer's positional information will be encoded into the k-mer before bundling. 
%%% picture
To encode biological information into the vectors, we used the last layer of the 3 billion-parameter ESM-2 model~\cite{esm2} of every amino acid, resulting in 1024-dimensional real-valued embeddings for every amino acid. To extend these into hyperdimensions, a simple matrix multiplication has been employed: $A_{1x1024}X B_{1024x10000} = C_{1x10000}$ where $A$ is an ESM-2 embedding and B a matrix of 1024 random 10000-D vectors. The resulting vectors are then min-max scaled and rounded depending on the desired nature of the vectors.
\subsection*{Type classification}
Out of the 11549 unambiguous UniParc accessions in the newest version of the database, 4829 are manually annotated on their type. Out of these manually annotated proteins, 2803 are endolysins and 2026 are VALs. As a baseline level, we use the rudimentary HDV classification technique as seen in chapter~\ref{sec:example}: the HDVs of sequences of the same class are bundled to construct single HDVs representative of every class. Then, a sequence's class is inferred by comparing the sequence's HDV to both class HDV \textit{via} a similarity measure based on the assumption that the class vector is maximally similar to its components. This model was evaluated \textit{via} a stratified 10-fold cross validation. The classification with an XGBoost classifier is done via the default XGBoost classifier from \textit{XGBoost.jl v2.2.5} and is evaluated \textit{via} \text{MLJ.jl v0.19.5} with also a stratified 10-fold cross validation..